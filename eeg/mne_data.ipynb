{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80a188ea-1c3d-410e-8e62-69164f019ac1",
   "metadata": {},
   "source": [
    "# Exploring MNE's data structure\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "- Import raw EEG data using MNE\n",
    "- Examine the structure of an MNE `Raw` object\n",
    "- Access and view different attributes of a `Raw` data object\n",
    "- Visualize the positions of EEG electrodes \n",
    "\n",
    "\n",
    "---\n",
    "## Introduction\n",
    "\n",
    "In this lesson, we will load a raw EEG data file using MNE and gain an understanding of how MNE stores data. This is an important first step to working with data in MNE.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f49c294-5e2c-4678-ba98-3601061b1170",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load pacakges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6a2ddc56-2655-4f02-8b13-96a47db5da5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202e8168-e748-47fb-ac2b-685bc946e8c5",
   "metadata": {},
   "source": [
    "## Import raw data\n",
    "\n",
    "For EEG, raw data is typically stored in a single file containing continuous EEG data. There are many different file formats for EEG data; most of these are developed by the manufacturer or a particular EEG system. Fortunately, MNE provides functions to import data from most common EEG systems. \n",
    "\n",
    "In the present case, we are working with data from a system sold by Brain Products, whose software is called *Brain Vision*. So we will use MNE's `read_raw_brainvision()` function. As described previously, many of MNE's functions are nested inside subfolders (modules); for example, all of the file input-output (I/O) routines are in the module `mne.io`. So when we call the `read_raw_brainvision()` function, we have to do so as `mne.io.read_raw_brainvision()`. The one required argument for this function is the file name, and that's all we need for now: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "58516da4-96c2-4552-93dd-99df86731bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting parameters from data/P4.vhdr...\n",
      "Setting channel info structure...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x0/pvpjfdzd39sc5rqvsk5lvv4m0000gn/T/ipykernel_39870/1158076128.py:1: RuntimeWarning: Online software filter detected. Using software filter settings and ignoring hardware values\n",
      "  raw = mne.io.read_raw_brainvision('data/P4.vhdr')\n"
     ]
    }
   ],
   "source": [
    "raw = mne.io.read_raw_brainvision('data/P4.vhdr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0930a7-3e8b-4bca-9767-6244110a0ea6",
   "metadata": {},
   "source": [
    "You may notice above, and throughout this lesson, that MNE provides a lot output, and often some concerning-looking Python warning messages. Most of these warnings are safely ignored. In subsequent lessons we'll see how to reduce the amount of output MNE generates, since it often consumes a lot of space in a notebook, and is not terribly useful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f30d27-7ccf-427a-82e8-4bd3d31a6293",
   "metadata": {},
   "source": [
    "### View raw data attributes\n",
    "\n",
    "We now have our raw EEG data represented in Python as an MNE `Raw` object. We can view it's basic information by asking for the `.info` property:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fd09952e-1a6a-4485-85e2-e3f349ade412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table class=\"table table-hover\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "        <td>March 08, 2017  09:05:29 GMT</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "<td>Unknown</td>\n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "<td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>0 magnetometer, 0 gradiometer,\n",
       "            and 16 EEG channels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td></td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>Not available</td>\n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>500.00 Hz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>0.01 Hz</td>\n",
       "    </tr>\n",
       "     <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>80.00 Hz</td>\n",
       "    </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<Info | 7 non-empty values\n",
       " bads: []\n",
       " ch_names: Fp1, F3, F7, C3, P3, TP9, Fz, Cz, Fp2, F4, F8, C4, P4, TP10, Pz, Oz\n",
       " chs: 16 EEG\n",
       " custom_ref_applied: False\n",
       " highpass: 0.0 Hz\n",
       " lowpass: 80.0 Hz\n",
       " meas_date: 2017-03-08 09:05:29 UTC\n",
       " nchan: 16\n",
       " projs: []\n",
       " sfreq: 500.0 Hz\n",
       ">"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a269c9-f80e-4e8d-9b11-4e3335613f3f",
   "metadata": {},
   "source": [
    "Although some of the information is not available, this shows us a few important things about our data set, including that there are 16 EEG channels (each channel contains the data from one EEG electrode), that the sampling rate is 500 Hz (i.e., EEG data were sampled 500 times per second, so we have a data point every 2 ms), and that the data were filtered during data collection between 0.01–80 Hz (more on filtering below).\n",
    "\n",
    "The information provided above is actually a subset of the information stored in the `Raw` object's `info`. We can use the `.keys()` method to see all of the fields available in `info`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "51533952-d21c-4570-a350-ba151f707b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['acq_pars', 'acq_stim', 'ctf_head_t', 'description', 'dev_ctf_t', 'dig', 'experimenter', 'utc_offset', 'device_info', 'file_id', 'highpass', 'hpi_subsystem', 'kit_system_id', 'helium_info', 'line_freq', 'lowpass', 'meas_date', 'meas_id', 'proj_id', 'proj_name', 'subject_info', 'xplotter_layout', 'gantry_angle', 'bads', 'chs', 'comps', 'events', 'hpi_meas', 'hpi_results', 'projs', 'proc_history', 'custom_ref_applied', 'sfreq', 'dev_head_t', 'ch_names', 'nchan'])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.info.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05628b30-1567-4ce9-a7aa-6a4893e1b6c4",
   "metadata": {},
   "source": [
    "We can access the values stored with any of these info attributes by putting it in square brackets, like this command to access the names of all of the channels (electrodes) in the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0c718ce2-8d39-48b0-a988-058fbc0f5638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fp1',\n",
       " 'F3',\n",
       " 'F7',\n",
       " 'C3',\n",
       " 'P3',\n",
       " 'TP9',\n",
       " 'Fz',\n",
       " 'Cz',\n",
       " 'Fp2',\n",
       " 'F4',\n",
       " 'F8',\n",
       " 'C4',\n",
       " 'P4',\n",
       " 'TP10',\n",
       " 'Pz',\n",
       " 'Oz']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.info['ch_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b95a16-31c7-412c-b120-784eba6f7043",
   "metadata": {},
   "source": [
    "The `info` is a snapshot of a few pieces of information that researchers may want to know about a data file, but it's far less than all the information stored in the MNE `Raw` object. To see the entire contents of the object, we can ask for it's `__dict__` (note that there are two underscores below `dict` and two after). Recall that `Raw` is a Python class, and any instance of the `Raw` class (such as our `raw` data here) is a Python object. Any Python object has an atrribute `__dict__`, and this attribute contains a dictionary of all of the object's attributes, with keys being the attribute names, and values being the information stored for that attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2a3e2259-7f81-453d-a048-e4c4e0af73f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'preload': False,\n",
       " '_last_samps': array([682589]),\n",
       " '_first_samps': array([0]),\n",
       " 'info': <Info | 7 non-empty values\n",
       "  bads: []\n",
       "  ch_names: Fp1, F3, F7, C3, P3, TP9, Fz, Cz, Fp2, F4, F8, C4, P4, TP10, Pz, Oz\n",
       "  chs: 16 EEG\n",
       "  custom_ref_applied: False\n",
       "  highpass: 0.0 Hz\n",
       "  lowpass: 80.0 Hz\n",
       "  meas_date: 2017-03-08 09:05:29 UTC\n",
       "  nchan: 16\n",
       "  projs: []\n",
       "  sfreq: 500.0 Hz\n",
       " >,\n",
       " 'buffer_size_sec': 1.0,\n",
       " 'verbose': None,\n",
       " '_cals': array([4.88281e-08, 4.88281e-08, 4.88281e-08, 4.88281e-08, 4.88281e-08,\n",
       "        4.88281e-08, 4.88281e-08, 4.88281e-08, 4.88281e-08, 4.88281e-08,\n",
       "        4.88281e-08, 4.88281e-08, 4.88281e-08, 4.88281e-08, 4.88281e-08,\n",
       "        4.88281e-08]),\n",
       " '_raw_extras': [{'offsets': None,\n",
       "   'fmt': 'single',\n",
       "   'order': 'F',\n",
       "   'n_samples': 682590,\n",
       "   'orig_nchan': 16}],\n",
       " '_read_picks': [array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])],\n",
       " '_read_comp_grade': None,\n",
       " '_comp': None,\n",
       " '_filenames': ['/Users/aaron/NESC3505/NESC_3505_textbook/eeg/data/P4.eeg'],\n",
       " 'orig_format': 'single',\n",
       " '_orig_units': {'Fp1': 'µV',\n",
       "  'F3': 'µV',\n",
       "  'F7': 'µV',\n",
       "  'C3': 'µV',\n",
       "  'P3': 'µV',\n",
       "  'TP9': 'µV',\n",
       "  'Fz': 'µV',\n",
       "  'Cz': 'µV',\n",
       "  'Fp2': 'µV',\n",
       "  'F4': 'µV',\n",
       "  'F8': 'µV',\n",
       "  'C4': 'µV',\n",
       "  'P4': 'µV',\n",
       "  'TP10': 'µV',\n",
       "  'Pz': 'µV',\n",
       "  'Oz': 'µV'},\n",
       " '_projectors': [],\n",
       " '_projector': None,\n",
       " '_dtype_': numpy.float64,\n",
       " '_annotations': <Annotations | 154 segments: Comment/actiCAP Data On (1), Comment/actiCAP ...>,\n",
       " '_init_kwargs': {'vhdr_fname': '/Users/aaron/NESC3505/NESC_3505_textbook/eeg/data/P4.vhdr',\n",
       "  'eog': ('HEOGL', 'HEOGR', 'VEOGb'),\n",
       "  'misc': 'auto',\n",
       "  'scale': 1.0,\n",
       "  'preload': False,\n",
       "  'verbose': None},\n",
       " 'impedances': {}}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254f8f0b-bb4a-4887-babe-e23e25182e7a",
   "metadata": {},
   "source": [
    "## Where's the data?\n",
    "\n",
    "For all the information that is in the output above, one thing you may have noticed is that there doesn't seem to be any actual EEG data! This is because, by default, MNE's routines to read raw data read the data file's *header* into memory, but not the data itself. The reason for this is that data files are often quite large, and so reading them in sometimes takes a noticeable amount of time, and consume significant memory. The header of a raw EEG data file contains its metadata (information about the file), as you saw above in printing out the `__dict__` this is often enough for MNE to perform some operations on the data. At some point, if you want to perform operations on the EEG data, then MNE will automatically load in the data to work on it. \n",
    "\n",
    "We can force MNE to load in the data when we read the file, with the `preload` kwarg. We'll do this now so that we can look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "64f34e47-24fe-4630-817a-e6a38af306d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting parameters from data/P4.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 682589  =      0.000 ...  1365.178 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x0/pvpjfdzd39sc5rqvsk5lvv4m0000gn/T/ipykernel_39870/4236418496.py:1: RuntimeWarning: Online software filter detected. Using software filter settings and ignoring hardware values\n",
      "  raw = mne.io.read_raw_brainvision(raw_file, preload=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'_last_samps': array([682589]),\n",
       " '_first_samps': array([0]),\n",
       " 'info': <Info | 7 non-empty values\n",
       "  bads: []\n",
       "  ch_names: Fp1, F3, F7, C3, P3, TP9, Fz, Cz, Fp2, F4, F8, C4, P4, TP10, Pz, Oz\n",
       "  chs: 16 EEG\n",
       "  custom_ref_applied: False\n",
       "  highpass: 0.0 Hz\n",
       "  lowpass: 80.0 Hz\n",
       "  meas_date: 2017-03-08 09:05:29 UTC\n",
       "  nchan: 16\n",
       "  projs: []\n",
       "  sfreq: 500.0 Hz\n",
       " >,\n",
       " 'buffer_size_sec': 1.0,\n",
       " 'verbose': None,\n",
       " '_cals': array([4.88281e-08, 4.88281e-08, 4.88281e-08, 4.88281e-08, 4.88281e-08,\n",
       "        4.88281e-08, 4.88281e-08, 4.88281e-08, 4.88281e-08, 4.88281e-08,\n",
       "        4.88281e-08, 4.88281e-08, 4.88281e-08, 4.88281e-08, 4.88281e-08,\n",
       "        4.88281e-08]),\n",
       " '_raw_extras': [{'offsets': None,\n",
       "   'fmt': 'single',\n",
       "   'order': 'F',\n",
       "   'n_samples': 682590,\n",
       "   'orig_nchan': 16}],\n",
       " '_read_picks': [array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])],\n",
       " '_read_comp_grade': None,\n",
       " '_comp': None,\n",
       " '_filenames': ['/Users/aaron/NESC3505/NESC_3505_textbook/eeg/data/P4.eeg'],\n",
       " 'orig_format': 'single',\n",
       " '_orig_units': {'Fp1': 'µV',\n",
       "  'F3': 'µV',\n",
       "  'F7': 'µV',\n",
       "  'C3': 'µV',\n",
       "  'P3': 'µV',\n",
       "  'TP9': 'µV',\n",
       "  'Fz': 'µV',\n",
       "  'Cz': 'µV',\n",
       "  'Fp2': 'µV',\n",
       "  'F4': 'µV',\n",
       "  'F8': 'µV',\n",
       "  'C4': 'µV',\n",
       "  'P4': 'µV',\n",
       "  'TP10': 'µV',\n",
       "  'Pz': 'µV',\n",
       "  'Oz': 'µV'},\n",
       " '_projectors': [],\n",
       " '_projector': None,\n",
       " '_dtype_': numpy.float64,\n",
       " '_annotations': <Annotations | 154 segments: Comment/actiCAP Data On (1), Comment/actiCAP ...>,\n",
       " '_data': array([[-2.67079217e-05, -3.40180700e-05, -3.36670703e-05, ...,\n",
       "         -3.08213636e-01, -3.08150990e-01, -3.08088343e-01],\n",
       "        [-1.09543744e-06, -7.06529256e-07,  4.21714567e-07, ...,\n",
       "          3.56437879e-01,  3.56370032e-01,  3.56302186e-01],\n",
       "        [ 1.18619858e-05,  1.43045352e-05,  2.06130876e-05, ...,\n",
       "         -3.21511579e-01, -3.21447589e-01, -3.21383600e-01],\n",
       "        ...,\n",
       "        [-4.71284208e-05, -4.18195153e-05, -3.77398298e-05, ...,\n",
       "         -3.36509740e-01, -3.36444701e-01, -3.36379637e-01],\n",
       "        [-1.77195458e-05, -1.72090919e-05, -1.30532198e-05, ...,\n",
       "          3.73319584e-01,  3.73250053e-01,  3.73180546e-01],\n",
       "        [-3.49426091e-05, -3.36795634e-05, -2.86693426e-05, ...,\n",
       "         -3.19992683e-01, -3.19929304e-01, -3.19865950e-01]]),\n",
       " 'preload': True,\n",
       " '_init_kwargs': {'vhdr_fname': '/Users/aaron/NESC3505/NESC_3505_textbook/eeg/data/P4.vhdr',\n",
       "  'eog': ('HEOGL', 'HEOGR', 'VEOGb'),\n",
       "  'misc': 'auto',\n",
       "  'scale': 1.0,\n",
       "  'preload': True,\n",
       "  'verbose': None},\n",
       " 'impedances': {}}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = mne.io.read_raw_brainvision(raw_file, preload=True)\n",
    "\n",
    "raw.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9c3da5-fb95-4ed6-bfa0-17859f969516",
   "metadata": {},
   "source": [
    "Now we can see that there is a `_data` attribute, containing a NumPy array. We can access the data like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5cc989e5-1fcc-4cb7-a1f5-b558ffc5faab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(16, 682590)\n"
     ]
    }
   ],
   "source": [
    "print(type(raw._data))\n",
    "print(raw._data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6ee19b-bb1d-4cd0-96ca-2ad1b9626244",
   "metadata": {},
   "source": [
    "MNE represents the data as a 2D array with a row for each channel, and columns for time points. We can derive the length of the EEG recording, in seconds, by dividing the number of time points by the sampling rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "42e1cfd2-c6a2-46e0-9a7c-daf5dcac10bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration of EEG recording =  1365.18 s, or 22.753 min.\n"
     ]
    }
   ],
   "source": [
    "scan_durn = raw._data.shape[1] / raw.info['sfreq']\n",
    "print('Duration of EEG recording = ', scan_durn, 's, or', scan_durn / 60, 'min.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef76c073-230b-4f9a-90b2-d9ad68a87ed6",
   "metadata": {},
   "source": [
    "## Accessing subsets of data\n",
    "\n",
    "Since the data is stored as a NumPy array, we can access specific data points using standard indexing. For example, if we wanted to select all of the data from only channel 15, we would use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "df57a294-98ff-4365-9bac-70439a4530de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.49426091e-05 -3.36795634e-05 -2.86693426e-05 ... -3.19992683e-01\n",
      " -3.19929304e-01 -3.19865950e-01]\n"
     ]
    }
   ],
   "source": [
    "print(raw._data[15, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9854907-e71b-4028-83ff-2cf07c5c016f",
   "metadata": {},
   "source": [
    "Likewise, if we wanted to access only the first 10 time points of channel 8, we would use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8c3ef8ea-3b22-43cc-9ea5-f967b2fc456b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00021124 0.00021153 0.00021526 0.00022065 0.00022381 0.0002228\n",
      " 0.00022086 0.00022152 0.00022406 0.00022598 0.00022798]\n"
     ]
    }
   ],
   "source": [
    "print(raw._data[8, :11])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d2df57-9392-47d3-bdb9-a935733c39c3",
   "metadata": {},
   "source": [
    "One challenge in working with the raw data directly in this way, is that we normally think of, and work with, EEG data in terms of units of time, such as seconds or milliseconds. However, EEG data is not always (or even usually) sampled at 1000 Hz, so each time point doesn't correspond to 1 ms. For example, in our current data set, the sampling rate was 500 Hz, so each time point reflects a period of 2 ms. This makes accessing specific time points or time ranges in the data tricky, because if you want, say, the data from 1500-1800 ms in the `raw` data, you would need to first convert those times to seconds (since `sfreq` is in samples per second), oncvert the result to `int` (since division is likely to yield a `float` result), then multiply each of those times by the sampling rate to get the correct indices. While this is not necessarily difficult, it's a bit tricky and prone to error, as well as creating complex code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "05ad474b-b6a2-4644-8291-b26132590d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00018245, 0.00018437, 0.00018864, 0.00019457, 0.00019848,\n",
       "       0.00019798, 0.00019517, 0.00019331, 0.00019327, 0.00019501,\n",
       "       0.00019897, 0.00020431, 0.00020803, 0.00020714, 0.0002027 ,\n",
       "       0.00019861, 0.00019641, 0.00019518, 0.00019454, 0.00019453,\n",
       "       0.00019386, 0.00019153, 0.00018945, 0.00018907, 0.0001888 ,\n",
       "       0.00018899, 0.00019214, 0.00019711, 0.00020056, 0.00020286,\n",
       "       0.00020605, 0.00020858, 0.00020825, 0.00020669, 0.00020621,\n",
       "       0.00020703, 0.00020843, 0.00020945, 0.00021   , 0.00021019,\n",
       "       0.0002085 , 0.00020438, 0.00020072, 0.00020058, 0.00020341,\n",
       "       0.00020607, 0.00020706, 0.00020666, 0.00020411, 0.00019923,\n",
       "       0.00019499, 0.00019539, 0.00020034, 0.00020524, 0.0002075 ,\n",
       "       0.00020769, 0.00020545, 0.00020112, 0.00019691, 0.00019422,\n",
       "       0.00019391, 0.00019645, 0.00020019, 0.00020246, 0.00020222,\n",
       "       0.0001997 , 0.00019523, 0.00019023, 0.00018778, 0.00019002,\n",
       "       0.00019562, 0.00020115, 0.00020264, 0.00019867, 0.000194  ,\n",
       "       0.00019433, 0.00019933, 0.00020523, 0.00020942, 0.00021133,\n",
       "       0.00021113, 0.00020858, 0.00020462, 0.00020216, 0.00020332,\n",
       "       0.00020762, 0.00021293, 0.00021691, 0.00021779, 0.00021543,\n",
       "       0.00021212, 0.00021039, 0.00021111, 0.00021463, 0.00022007,\n",
       "       0.00022462, 0.00022677, 0.00022727, 0.0002261 , 0.0002232 ,\n",
       "       0.00022106, 0.00022189, 0.00022526, 0.00023023, 0.00023543,\n",
       "       0.00023825, 0.00023812, 0.00023738, 0.00023718, 0.00023695,\n",
       "       0.00023741, 0.00023942, 0.00024243, 0.00024562, 0.00024795,\n",
       "       0.00024888, 0.00024939, 0.00025169, 0.00025767, 0.00026505,\n",
       "       0.00026985, 0.00027485, 0.00028527, 0.00029842, 0.00030838,\n",
       "       0.00031412, 0.00031789, 0.00032193, 0.00032744, 0.00033402,\n",
       "       0.00034016, 0.00034477, 0.0003477 , 0.0003484 , 0.00034782,\n",
       "       0.00034937, 0.00035373, 0.00035726, 0.00035742, 0.00035541,\n",
       "       0.00035342, 0.00035181, 0.00035078, 0.00035245, 0.00035672,\n",
       "       0.00035879, 0.00035553, 0.00034966, 0.00034424, 0.00033889])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chan = 8 # set channel we want\n",
    "start_time = int((1500 / 1000) * raw.info['sfreq'])\n",
    "end_time   = int((1800 / 1000) * raw.info['sfreq'])\n",
    "raw._data[chan, start_time:end_time]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa64451-714f-48fa-a2c4-62e97b05b5e7",
   "metadata": {},
   "source": [
    "## Accessing data using MNE tools\n",
    "\n",
    "Fortunately, since MNE is made to work with EEG data, it has lots of functions and methods that make it easy to do common tasks. Besides convenience, it's generally a good idea to use these because in general they provide an API that is more intuitive to use, and also create less risk that you will corrupt the data (since if you're using `._data`, it would be easy to accidentally assign new values to the array, or otherwise modify it, and Python would not warn you that you were doing something bad).\n",
    "\n",
    "We can access the data in an MNE object with the `.get_data()` method. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4b8ec3c4-2e82-46bb-a5df-7f42fc99674f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 682590)\n"
     ]
    }
   ],
   "source": [
    "raw_data = raw.get_data()\n",
    "print(raw_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effb6c47-19a5-40f2-b872-64b5b1116778",
   "metadata": {},
   "source": [
    "Moreover, `.get_data()` provides kwargs that allow us to select channels and time ranges, using more intuitive units like channel labels, and times, rathter than NumPy array indices. `picks` is used to select the channel (or channels if you pass a list), and `tmin` and `tmax` specify the range of time that you want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "416f75d4-6bdd-47d2-84c3-d4d2b76a21f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_data() got an unexpected keyword argument 'tmin'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/x0/pvpjfdzd39sc5rqvsk5lvv4m0000gn/T/ipykernel_39870/249292067.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpicks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Fz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Cz'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: get_data() got an unexpected keyword argument 'tmin'"
     ]
    }
   ],
   "source": [
    "raw.get_data(picks=['Fz', 'Cz'], tmin=1.5, tmax=1.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "663ba45b-d6e0-46b8-bb06-ac381e475969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.23.0'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mne.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e559ead-723f-40cf-841a-d8337e534086",
   "metadata": {},
   "source": [
    "### Set electrode positions\n",
    "\n",
    "One thing that can be useful at this stage is visualizing the electrode positions on the head. Typically, EEG studies try to position electrode in a fairly evenly-spaced way over the top of the head. However, the locations can depend someone on what ERP [components](./components) are predicted for the study, and how many electrodes are available. \n",
    "\n",
    "MNE provides a `.plot_sensors()` method for visualizing sensor locations. However, by default although our raw data contains the *names* of each channel, it does not contain information regarding where each channel was located. Fortunately, in this and most EEG studies, the electrode positions were based on the International 10-20 system. This was first introduced as a way of standardizing EEG electrode placement in clinical neurology, and is so-named because electrode positions are determined by first measuring the anterior-posterior and left-right dimensions of the participant's head, and then placing electrodes at positions determined by 10 and 20% increments of those measurements (E.g., electrode Cz is placed 50% of the anterior-posterior and left-right measurements). More recently, [Oostenveld and Praamstra (2001)](https://doi.org/10.1016/S1388-2457(00)00527-7) published an extension of this called the 10-5 system, that allows for a larger number of electrodes based on 5% increments. You can read more about this system and its variants on [Oostenveld's blog](https://robertoostenveld.nl/electrode/#oostenveld2001). \n",
    "\n",
    "Long story short, we have to first run an MNE method to look up the locations of each electrode based on its 10-20 system name, and set the positions in the raw file. We do this with `.set_montage()`, and as an argument use MNE's built-in list of 10-5 system electrode names and locations.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "**Note:** *Montage* is a common word used to describe the arrangement of EEG electrodes on a head, or in an EEG cap. In more general usage, *montage* means \"a collection of elements\".</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebfec28-458f-47d8-b668-9edeb717eac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.set_montage('standard_1005')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fbb447-7311-4880-9ff5-5359043c705c",
   "metadata": {},
   "source": [
    "MNE prints out the `info` for the `Raw` object again, and if you compare this output to that from earlier, you'll see that the *Digitized points* field has changed from \"Not available\" to \"19 points\". This terminology is a bit strange - \"digitized points\" seems more general and nonspecific than \"electrode locations\", for example. The reason for this is that in some cases, researchers will actually use a device to digitize the locations of electrodes when they are on a person's head, rather than relying on standard positions. Anyway, this information is stored under the `dig` attribute, which we can view with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b6ea02-ee05-4148-bdfe-e30d773db376",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.info['dig']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a6193a-47c3-410f-97da-a1f3ebb72db6",
   "metadata": {},
   "source": [
    "Each electrode location is stored as a set of (*x*, *y*, *z*) Cartesian coordinates, i.e., positions in a 3D grid, where *x* is the left-right dimension, *y* is posterior-anterior, and *z* is inferior-posterior. The (0, 0, 0) location is inside the head, located in a plane defined by the bridge of the nose (called the **nasion**) and the left and right ear canals. As shown in the figure below, *x* goes from left (negative) to right (positive), *y* goes from posterior to anterior, and *z* goes from inferior to superior. In general, you won't need to work with this coordinate system directly, but it's useful to know how the data are represented."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1573ae8-af6e-4c62-9dce-9da5164abc0e",
   "metadata": {},
   "source": [
    "![cartesian coordinate system for electrode positions](images/MRI_ax_sag_cor.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76de5e9-2788-4888-8f85-04c13f10ae62",
   "metadata": {},
   "source": [
    "### View electrode positions\n",
    "\n",
    "MNE provides tools for viewing channel locations in both 2D and 3D:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a258637-37f1-4ff8-b2cd-66ea92da54a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.plot_sensors()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8236895e-c413-4397-96c2-e825e163e903",
   "metadata": {},
   "source": [
    "### MNE plots in Jupyter notebooks\n",
    "\n",
    "You'll notice above that MNE actually drew two copies of the figure. This is a default behaviour of MNE for many plots, and it's annoying if you don't know how to deal with it. There are two ways to ensure MNE produces only a single copy of a figure:\n",
    "- end the plot command with a semicolon\n",
    "- put `plt.show()` at the bottom of the cell (or at least after all plotting commands in the cell)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ba4fbb-854d-412c-807b-71158f1b8316",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.plot_sensors();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecc2724-9ff5-4ea3-bd57-d915aa8e09fc",
   "metadata": {},
   "source": [
    "Below we demonstrate the `plt.show()` approach, and add a kwarg to show the names of each sensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bce7e6c-2e71-4c73-83f7-3890839a7017",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.plot_sensors(show_names=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536eb936-70b9-439e-9088-1ebb25ddcad4",
   "metadata": {},
   "source": [
    "- view the whole raw object\n",
    "- view the list of channel names\n",
    "- view/extract the data \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
