{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working With Multiple Data Files Using Copilot\n",
    "\n",
    "In this lesson we will revisit some of the material covered at the end of the introductory chapter on Python. Specifically, reading multiple data files, manipulating the data using pandas, and deriving some basic information from the data.\n",
    "\n",
    "The instructions are very high-level, because we want you to work on writing Copilot prompts yourself, based on high-level instructions rather than us giving you step-by step guidance. The version of this lesson in the online textbook, however, shows the worked example with prompts and Copilot-generated code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "Your task is to perform the operations below, using Python code generated by a combination of your own writing, and GitHub Copilot's suggestions. For your own learning, you are best off to start each step by trying to write the code yourself. If it works, great – you've learned something in Python! Congratulations. \n",
    "\n",
    "If it doesn't work, then you can try again, or use Copilot to help you out. Copilot is meant to speed up your coding, so in practice it's preferable to use it to help you out when you get stuck, than spend too much time trying to figure out how to do something yourself. On the other hand, once you have the solution from Copilot, it's important to try to understand what it is doing. You may have to look up some of the functions it's using, if you're not familiar with them. The tasks below intentionally ask you to do things that we haven't taught in this course yet. That's because we want you to learn how to use Copilot to help you out when you don't know how to do something.\n",
    "\n",
    "However, if you're ignorant of what the code you generated is doing, you risk errors, or simply not being able to explain correctly what you did. Also, look for ways to check that the results you get are correct (using code). \n",
    "\n",
    "### The Data and What to Do With It\n",
    "\n",
    "There are three data files in the `data` directory: `s1.csv`, `s2.csv`, and `s3.csv`. Each file contains the reaction times (RTs) from 10 trials of a relatively simple task in which participants had to indicate which direction a briefly-presented arrow was pointing. The RTs are in seconds (s). Each file contains the RTs from a different participant. In each file there are three columns. You can determine what the columns are by looking at the first row (header) of each file.\n",
    "\n",
    "Generate code that reads in the three files and combines them in a pandas DataFrame. Include error-checking  code that determines you loaded in the correct number of trials (30) and the correct number of columns (3). If the number of trials or columns is incorrect, print an error message.\n",
    "\n",
    "Save the dataframe to a file called `all_data.csv`, in the `data` folder.\n",
    "\n",
    "Once you have the DataFrame, calculate:\n",
    "- the mean RT for each participant\n",
    "- the mean RT across all participants\n",
    "- the 95% confidence intervals for the mean RT for each participant\n",
    "- the 95% confidence intervals for the mean RT across all participants\n",
    "\n",
    "Print all of the above results to the screen, rounded to 2 decimal places and with accompanying text that indicates what each result is. Be sure that it is clear that RT is in seconds.\n",
    "\n",
    "As well, generate a plot of the mean RT for each participant, with error bars showing the 95% confidence intervals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Approach This Exercise\n",
    "\n",
    "A critical skill to develop in coding is **problem decomposition** – in other words, breaking down a task into smaller and smaller components, so that you can write the code to perform each step in the logical sequence. The instructions above are written in a sequential way, so you should be able to identify each individual step that  you need to take.\n",
    "\n",
    "It is good practice, when working in Jupyter notebooks, to write the code for each step in a separate cell. This makes it easier to test each step, and to go back and change things if you need to. It also makes it easier to see what you've done, and understand what the code is doing. As well, it's sometime helpful to put Markdown cells in between code cells, to provide longer explanations than might be appropriate for a comment in the code itself. You can also make notes about things you might want to change later, or interpretations of the output of the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Copilot Assistant\n",
    "\n",
    "As noted above, we encourage you to try writing the code for each step of the instructions above. Coding is a *procedural* skill that you only learn by doing — and the more you learn the better you will be at solving the bugs that Copilot-generated code will inevitably have. But, if you get stuck, or encounter an instruction that you haven't yet learned how to perform in Python, then by all means use Copilot. Just like writing your own code, it is best if you use a separate notebook cell for each Copilot prompt. That way, if you need to edit the code, you can do so without having to re-run all of the code that Copilot generated. It's also easier to debug because you can see the output of each cell and now exactly which line generated the error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copilot-Generated Code for the Above\n",
    "\n",
    "The cells below all reflect prompts written on the basis of the instructions above, and code generated entirely by Copilot. As you will see, it takes some trial and error – and critical thinking – to generate prompts that produce the code you want. But, it's a good way to learn how to use Copilot effectively. And if you do it right, you will learn a lot about Python along the way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in three files from the data folder, whose names start with \"s\" and end in \"csv\"\n",
    "# concatenate them into one dataframe\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "\n",
    "# get a list of all the files in the data folder that start with \"s\" and end with \"csv\"\n",
    "file_list = glob.glob('data/s*.csv')\n",
    "\n",
    "\n",
    "# read in the files and concatenate them into one dataframe\n",
    "df = pd.concat([pd.read_csv(f) for f in file_list])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participantID</th>\n",
       "      <th>trial</th>\n",
       "      <th>RT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.433094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.392526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.396831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.417988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.371810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  participantID  trial        RT\n",
       "0            s2      1  0.433094\n",
       "1            s2      2  0.392526\n",
       "2            s2      3  0.396831\n",
       "3            s2      4  0.417988\n",
       "4            s2      5  0.371810"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the first 5 rows of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that the dataframe has 30 rows and 3 columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raise an error if the dataframe does not have 30 rows and 3 columns\n",
    "assert df.shape == (30, 3), \"The dataframe does not have 30 rows and 3 columns\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe as a csv file named \"all_subjects.csv\" in the data folder\n",
    "df.to_csv('data/all_subjects.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'subject'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# calculate mean rt for each subject\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df\u001b[39m.\u001b[39;49mgroupby(\u001b[39m'\u001b[39;49m\u001b[39msubject\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39mmean()\n",
      "File \u001b[0;32m~/mambaforge/envs/ncil/lib/python3.10/site-packages/pandas/core/frame.py:8252\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   8249\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mYou have to supply one of \u001b[39m\u001b[39m'\u001b[39m\u001b[39mby\u001b[39m\u001b[39m'\u001b[39m\u001b[39m and \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlevel\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   8250\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_axis_number(axis)\n\u001b[0;32m-> 8252\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameGroupBy(\n\u001b[1;32m   8253\u001b[0m     obj\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   8254\u001b[0m     keys\u001b[39m=\u001b[39;49mby,\n\u001b[1;32m   8255\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m   8256\u001b[0m     level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m   8257\u001b[0m     as_index\u001b[39m=\u001b[39;49mas_index,\n\u001b[1;32m   8258\u001b[0m     sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m   8259\u001b[0m     group_keys\u001b[39m=\u001b[39;49mgroup_keys,\n\u001b[1;32m   8260\u001b[0m     observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[1;32m   8261\u001b[0m     dropna\u001b[39m=\u001b[39;49mdropna,\n\u001b[1;32m   8262\u001b[0m )\n",
      "File \u001b[0;32m~/mambaforge/envs/ncil/lib/python3.10/site-packages/pandas/core/groupby/groupby.py:931\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropna \u001b[39m=\u001b[39m dropna\n\u001b[1;32m    930\u001b[0m \u001b[39mif\u001b[39;00m grouper \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     grouper, exclusions, obj \u001b[39m=\u001b[39m get_grouper(\n\u001b[1;32m    932\u001b[0m         obj,\n\u001b[1;32m    933\u001b[0m         keys,\n\u001b[1;32m    934\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m    935\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m    936\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m    937\u001b[0m         observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[1;32m    938\u001b[0m         dropna\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropna,\n\u001b[1;32m    939\u001b[0m     )\n\u001b[1;32m    941\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj \u001b[39m=\u001b[39m obj\n\u001b[1;32m    942\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_get_axis_number(axis)\n",
      "File \u001b[0;32m~/mambaforge/envs/ncil/lib/python3.10/site-packages/pandas/core/groupby/grouper.py:985\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[1;32m    983\u001b[0m         in_axis, level, gpr \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, gpr, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    984\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 985\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(gpr)\n\u001b[1;32m    986\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(gpr, Grouper) \u001b[39mand\u001b[39;00m gpr\u001b[39m.\u001b[39mkey \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    987\u001b[0m     \u001b[39m# Add key to exclusions\u001b[39;00m\n\u001b[1;32m    988\u001b[0m     exclusions\u001b[39m.\u001b[39madd(gpr\u001b[39m.\u001b[39mkey)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'subject'"
     ]
    }
   ],
   "source": [
    "# calculate mean rt for each subject\n",
    "df.groupby('subject').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging Copilot-Generated Code\n",
    "\n",
    "Typically, when you get a long, scary error message like the one above, you can ignore a lof of what is in the middle. The most important parts are the last line, which tells you what the error is, and the first lines, which usually indicate what line in the code you tried to run caused the error. \n",
    "\n",
    "In this case, we see a `KeyError: 'subject'` at the bottom of the error message. Recall that Python dictionaries are sets of **key**-value pairs. The keys are the names of the columns, and the values are the data in those columns. \n",
    "\n",
    "You can think of a pandas DataFrame as a dictionary in which the column names are keys, and the values in that column are its values. So the error message above indicates that the code tried to access a column called `subject` in the DataFrame, but that column doesn't exist. We can see at the top of the error message that the code that caused the error is: `---> 2 df.groupby('subject').mean()`. This means it's line 2 of the cell above that caused the error. \n",
    "\n",
    "As a novice coder, however, you might not know or remember that pandas DataFrames represent column names and data as dictionary key-value pairs. If you don't understand what an error means, you can use Copilot to help you!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copilot has a few features that can help you diagnose and fix your code. If you right-click in a code cell, you will see `Copilot` within the menu that pops up. Under that heading there are a number of options, including `Explain This` and `Fix This`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Copilot `Explain This`\n",
    "\n",
    "A great place to start in diagnosing errors is `Explain This`. Intuitively, you might go straight for `Fix This`. However, it's probably instructive to see what Copilot thinks your code is doing, and if that is what *you* think your code is doing. Copilot's explanation might give you insight into the error. Below is the output from selecting `Explain This` for the line of code that caused the error above:\n",
    "\n",
    "> This code is designed to calculate the mean reaction time (RT) for each subject in a dataframe. The code uses the groupby() method to group the data by the 'subject' column and then calculates the mean for each group using the mean() method.\n",
    ">\n",
    ">The resulting dataframe contains the mean RT for each subject. The index of the dataframe is the unique values in the 'subject' column, and the columns are the other numerical columns in the original dataframe.\n",
    ">\n",
    "> This code is useful when working with data that has multiple subjects and you want to calculate summary statistics for each subject. By using the groupby() method, you can easily calculate summary statistics for each group without having to manually subset the data.\n",
    ">\n",
    "> One possible way to improve this code would be to specify the column to calculate the mean for, rather than calculating the mean for all numerical columns. This would make the code more specific and reduce the risk of errors. Additionally, the code could be modified to calculate other summary statistics, such as the standard deviation or median, by using the appropriate method instead of the mean() method.\n",
    "\n",
    "First off, this shows how Copilot can be a great learning tool. It's giving us a clear explanation of what the code is doing, and teaching us a bit about how the `.groupby()` method works. It also suggests some improvements to the code, which we can take or leave.\n",
    "\n",
    "None of this explanation tells us directly why the code generates an error, but at least we have an explanation of what the code is actually doing, which we can use to help us figure out what is going wrong. \n",
    "\n",
    "The first paragraph of Copilot's explanation notes that the code is grouping the data by the `subject` column. This could be a clue to us, since the error message also references `subject`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copilot `Fix This`\n",
    "\n",
    "If you select `Fix This` from the Copilot menu, you will see what's called a **diff**, as shown below. A diff is a way of showing the difference between two pieces of code. The code on the left (with a pink background) is the code you wrote, and the code on the right (with a green background) is the code that Copilot suggests. In this case, the suggested \"fix\" would not fix the problem. \n",
    "\n",
    "![](images/copilot_fix_this.png)\n",
    "\n",
    "\n",
    "The suggested code is doing two things differently from the original code. Firstly, it's suggesting that you assign the output of the command to a variable, and then print the variable. Assigning output to a variable and then printing it is in general good coding style, because we may want to use that variable again later in our code. But that won't fix the error. A\n",
    "\n",
    "The other difference – which is subtle to a novice coder – is that the new code is referencing the column `Subject` rather than `subject`. Recall that Python is **case-sensitive**, meaning that `Subject` and `subject` are not the same thing. Copilot seems to be guessing that the error might be cause by a common mistake, which is to refer to a variable using the wrong case. \n",
    "\n",
    "\n",
    "You can click the `Discard` button to reject Copilot's suggestion, and the `Escape` key to exit the diff view.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Copilot does not generate the same code every time you type the same prompt. This is the nature of the type of generative AI that Copilot uses. So, when working through this lesson, you may get different outputs than what is shown in the lesson. Try to use the processes explained here for interpreting error messages and Copilot's descriptions and suggested code. It's much more important to get familiar with engaging in the process of debugging through the thought processes explained here, than to worry about getting different suggestions from Copilot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Copilot `Chat` \n",
    "\n",
    "![](images/chat_icon.png) Another, really useful option is the `Chat` option, which you can option by clicking the `Chat` icon in the Activity Bar (left side of VS Code). This allows you to have a conversation with Copilot about what you want to do. If you've used Chat-GPT before, this will be familiar to you.\n",
    "\n",
    "There are different approaches to using Copilot Chat to help fix an error. One is to click in the cell that generates the error, and then clicking in the Copilot Chat input box, and typing: `the selected cell generates an error. how can i fix this error?` In response to this prompt for the present error, I got the following response:\n",
    "\n",
    ">If you are getting an error with the selected cell, there could be a few reasons why. Here are some possible solutions:\n",
    ">\n",
    ">1. Check that the 'subject' column is present in the dataframe. You can do this by printing out the dataframe using the `print()` function and checking that the 'subject' column is present.\n",
    ">\n",
    ">2. Check that the 'subject' column is spelled correctly. If the column is misspelled, you will get a \"KeyError\" when trying to group by that column.\n",
    ">\n",
    ">3. Check that the 'subject' column is of the correct data type. If the 'subject' column is not a string or categorical data type, you may need to convert it using the `astype()` method.\n",
    ">\n",
    ">4. Check that the dataframe contains numerical columns. If the dataframe only contains non-numerical columns, you will get a \"DataError\" when trying to calculate the mean.\n",
    ">\n",
    ">5. Check that the dataframe does not contain missing values. If the dataframe contains missing values, you may need to remove them using the `dropna()` method before calculating the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the error\n",
    "\n",
    "These are actually really good responses, and provided in a logical order to go through in debugging. The first thing to do is to check that the column exists, and is spelled correctly. So let's start with that. Do you remember how to check the names of the columns in a pandas DataFrame? If not, you can write a Copilot prompt to help you out. In the cell below, write a prompt that will print the names of the columns in the DataFrame. Then run the cell, and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['participantID', 'trial', 'RT'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the column names of the dataframe\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the first few rows of the DataFrame, which includes the column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participantID</th>\n",
       "      <th>trial</th>\n",
       "      <th>RT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.433094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.392526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.396831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.417988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.371810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  participantID  trial        RT\n",
       "0            s2      1  0.433094\n",
       "1            s2      2  0.392526\n",
       "2            s2      3  0.396831\n",
       "3            s2      4  0.417988\n",
       "4            s2      5  0.371810"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the first few rows of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another option, when using Jupyter notebooks with VS Code, is to click on the `Variables` button in the toolbar at the top of the notebook window. This will pop up a variable viewer in sub-window below your notebook. You can click on the variable names to see their values. For DataFrames, it actually shows a list of the columns in the window, and you can double-click on the variable name to see the contents of the DataFrame in another window, the Data Viewer. This view is similar to a spreadsheet. In fact, you can directly edit values in the Data Viewer. *You should never directly edit values like this*, however. Any steps you do manually are not documented in your code, and are not reproducible.  \n",
    "\n",
    "The screenshot below shows the variables and Data Viewer for the current context.\n",
    "\n",
    "![](images/inspectors.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the column names, we see that they are `participantID`, `trial`, and `RT`. The code that generated the error was trying to access a column called `subject`, which doesn't exist. It should be `participantID`. So we need to change the code to access the correct column name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trial</th>\n",
       "      <th>RT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>participantID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>s1</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.389548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s2</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.444785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s3</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.446009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               trial        RT\n",
       "participantID                 \n",
       "s1               5.5  0.389548\n",
       "s2               5.5  0.444785\n",
       "s3               5.5  0.446009"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate mean rt for each subject\n",
    "df.groupby('participantID').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks good, however the code is providing means for both columns in the DataFrame, not just for `RT`. We can add to our prompt to tell it not to include trial in the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>participantID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>s1</th>\n",
       "      <td>0.389548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s2</th>\n",
       "      <td>0.444785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s3</th>\n",
       "      <td>0.446009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     RT\n",
       "participantID          \n",
       "s1             0.389548\n",
       "s2             0.444785\n",
       "s3             0.446009"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate mean rt for each subject. Do not show the mean for trial \n",
    "df.groupby('participantID').mean().drop('trial', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above generated code does what we want. However, from the perspectives of coding style and efficiency, it's not optimal. It seems unnecessary to compute the mean for `trial` and then drop it. We can modify the prompt in a way that generates more efficient code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "participantID\n",
       "s1    0.389548\n",
       "s2    0.444785\n",
       "s3    0.446009\n",
       "Name: RT, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate mean for each subject using the RT column\n",
    "df.groupby('participantID')['RT'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "One thing you may notice is that the above code prints the DataFrame in a less \"pretty\", formatted manner than the one before. This is not really important here, but it's worth understanding why the difference occurs. When you call a pandas DataFrame it prints in a nicely formatted output. However, when you call a pandas Series, it prints in a less formatted way. The output of the `groupby()` method on a single column (`RT`) is a Series, whereas the output of `.groupby()` on multiple columns (`trial` and `RT` is a DataFrame. In the first case, the code created a DataFrame and then dropped the `trial` column, but as such it remained a DataFrame. In contrast the output of using the `mean()` method on a single column is a Series.\n",
    "<p><p>\n",
    "We'll worry about the formatting later, but it's good to understand why it happens.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continue Coding\n",
    "\n",
    "Having fixed that error, we can now move on with the steps in the instructions. The next one was to calculate the mean RT across subjects. Do that below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'rt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/mambaforge/envs/ncil/lib/python3.10/site-packages/pandas/core/indexes/base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/mambaforge/envs/ncil/lib/python3.10/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/mambaforge/envs/ncil/lib/python3.10/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'rt'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# calculate the mean rt across all subjects\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df[\u001b[39m'\u001b[39;49m\u001b[39mrt\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mmean()\n",
      "File \u001b[0;32m~/mambaforge/envs/ncil/lib/python3.10/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3762\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/mambaforge/envs/ncil/lib/python3.10/site-packages/pandas/core/indexes/base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3655\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3656\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3657\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3660\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'rt'"
     ]
    }
   ],
   "source": [
    "# calculate the mean rt across all subjects\n",
    "df['rt'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I tried this, I got another `key Error`, this time for `RT`. This is because the code is trying to access a column called `rt`, but the column name is actually `rt`. AGain, let's start by trying to fix this ourselves, and then use Copilot if we get stuck. \n",
    "\n",
    "The code above selects the column in `df` called `rt` and computes its mean. However, if you look back to the listing of column names that we generated earlier, you'll see that the column name is actually `RT`. Python is **case sensitive**, meaning that capitalization matters: `RT` and `rt` are not the same. So we need to change the code to access the correct column name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4267806816333334"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['RT'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having fixed that error, let's move on to the next step, which is to calculate the 95% confidence intervals for the mean RT for each participant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'subject'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# calculate 95% confidence intervals for each subject\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df\u001b[39m.\u001b[39;49mgroupby(\u001b[39m'\u001b[39;49m\u001b[39msubject\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39mmean()\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39msem() \u001b[39m*\u001b[39m \u001b[39m1.96\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/mambaforge/envs/ncil/lib/python3.10/site-packages/pandas/core/frame.py:8252\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   8249\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mYou have to supply one of \u001b[39m\u001b[39m'\u001b[39m\u001b[39mby\u001b[39m\u001b[39m'\u001b[39m\u001b[39m and \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlevel\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   8250\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_axis_number(axis)\n\u001b[0;32m-> 8252\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameGroupBy(\n\u001b[1;32m   8253\u001b[0m     obj\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   8254\u001b[0m     keys\u001b[39m=\u001b[39;49mby,\n\u001b[1;32m   8255\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m   8256\u001b[0m     level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m   8257\u001b[0m     as_index\u001b[39m=\u001b[39;49mas_index,\n\u001b[1;32m   8258\u001b[0m     sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m   8259\u001b[0m     group_keys\u001b[39m=\u001b[39;49mgroup_keys,\n\u001b[1;32m   8260\u001b[0m     observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[1;32m   8261\u001b[0m     dropna\u001b[39m=\u001b[39;49mdropna,\n\u001b[1;32m   8262\u001b[0m )\n",
      "File \u001b[0;32m~/mambaforge/envs/ncil/lib/python3.10/site-packages/pandas/core/groupby/groupby.py:931\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropna \u001b[39m=\u001b[39m dropna\n\u001b[1;32m    930\u001b[0m \u001b[39mif\u001b[39;00m grouper \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     grouper, exclusions, obj \u001b[39m=\u001b[39m get_grouper(\n\u001b[1;32m    932\u001b[0m         obj,\n\u001b[1;32m    933\u001b[0m         keys,\n\u001b[1;32m    934\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m    935\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m    936\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m    937\u001b[0m         observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[1;32m    938\u001b[0m         dropna\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropna,\n\u001b[1;32m    939\u001b[0m     )\n\u001b[1;32m    941\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj \u001b[39m=\u001b[39m obj\n\u001b[1;32m    942\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_get_axis_number(axis)\n",
      "File \u001b[0;32m~/mambaforge/envs/ncil/lib/python3.10/site-packages/pandas/core/groupby/grouper.py:985\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[1;32m    983\u001b[0m         in_axis, level, gpr \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, gpr, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    984\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 985\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(gpr)\n\u001b[1;32m    986\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(gpr, Grouper) \u001b[39mand\u001b[39;00m gpr\u001b[39m.\u001b[39mkey \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    987\u001b[0m     \u001b[39m# Add key to exclusions\u001b[39;00m\n\u001b[1;32m    988\u001b[0m     exclusions\u001b[39m.\u001b[39madd(gpr\u001b[39m.\u001b[39mkey)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'subject'"
     ]
    }
   ],
   "source": [
    "# calculate 95% confidence intervals for each subject\n",
    "df.groupby('subject').mean().apply(lambda x: x.sem() * 1.96, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we get `Key Error: 'subject'`, which is the same as the first error above. So again, Copilot is labelling the column incorrectly. We know that we can fix this by replacing `subject` with `participantID`, but it's a bit annoying that Copilot keeps making this error. On the other hand, many errors are actually human errors. We are prompting Copilot to do something for each  \"subject\", which then requires Copilot to know that by \"subject\" we really mean the column called `participantID`. Maybe we could engineer our prompt to be better instead, by referring to the column name directly. Let's try that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "participantID\n",
       "s1    5.008243\n",
       "s2    4.954111\n",
       "s3    4.952911\n",
       "dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate 95% confidence intervals for each participantid\n",
    "df.groupby('participantID').mean().apply(lambda x: x.sem() * 1.96, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pink Elephants\n",
    "\n",
    "This is a frightening example of a Copilot **hallucination**. The above code generates what you might think is a plausible result. However, there are a couple of problems. Firstly, confidence intervals (CIs) are typically reported as a pair of values. The 95% CIs reflect the range within which it is 95% likely that the true mean lines, so we need an upper and lower range of these values. These are typically the same amount plus or minus from the mean. So we need to modify the code to generate the upper and lower values of the CIs. \n",
    "\n",
    "Secondly, if you look back at the mean RT for each participant, they were in the range of .339 – .449. Confidence intervals reflect the range of possible true values for the mean, given the sample data.  So for our confidence intervals to have values around 5 s seems implausible, given the mean RTs are < 500 ms. We would expect the CIs to be perhaps 100-200 ms. So it seems like Copilot is actually calculating the CIs incorrectly. \n",
    "\n",
    "This highlights the critical importance of understanding not only what your code is doing, but what you are asking it to do. You should always check the output of your code to make sure it makes sense, and also make sure you understand what you are supposed to be doing with the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copilot Chat to the Rescue\n",
    "\n",
    "We can use Copilot Chat to help us figure out what is going on. If we click on the `Chat` icon in the Activity Bar, we can type in a question to Copilot. In this case, I asked Copilot the following:\n",
    "\n",
    "> the highlighted code is supposed to compute the 95% confidence intervals of mean RT. However, the output values are incorrect. Can you please suggest code that correctly calculates the 95% confidence intervals, and provides both the upper and lower CIs in a table\n",
    "\n",
    "Copilot provided the answer below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> To correctly calculate the 95% confidence intervals for the mean RT and provide both the upper and lower CIs in a table, you can modify the existing code as follows:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# calculate mean and standard error of the mean for each participant\n",
    "mean_rt = df.groupby('participantID')['RT'].mean()\n",
    "sem_rt = df.groupby('participantID')['RT'].sem()\n",
    "\n",
    "# calculate 95% confidence intervals for the mean RT\n",
    "ci_rt = sem_rt * 1.96\n",
    "\n",
    "# calculate upper and lower CIs\n",
    "upper_ci = mean_rt + ci_rt\n",
    "lower_ci = mean_rt - ci_rt\n",
    "\n",
    "# create a table of the upper and lower CIs\n",
    "ci_table = pd.DataFrame({'Upper CI': upper_ci, 'Lower CI': lower_ci})\n",
    "\n",
    "# print the table of CIs\n",
    "print(ci_table)\n",
    "```\n",
    "\n",
    ">> In this code, the `groupby()` method is used to group the data by the 'participantID' column, and the `mean()` and `sem()` methods are used to calculate the mean and standard error of the mean for the 'RT' column for each group. The resulting series contains the mean and SEM for each unique value in the 'participantID' column.\n",
    ">> \n",
    ">> The `ci_rt` variable calculates the 95% confidence intervals for the mean RT using the formula `SEM * 1.96`, where `SEM` is the standard error of the mean.\n",
    ">> \n",
    ">> The `upper_ci` and `lower_ci` variables calculate the upper and lower CIs by adding and subtracting the `ci_rt` value from the `mean_rt` value, respectively.\n",
    ">> \n",
    ">> The `ci_table` variable creates a table of the upper and lower CIs using the `pd.DataFrame()` function.\n",
    ">> \n",
    ">> Finally, the `print()` function is used to print the table of CIs.\n",
    ">> \n",
    ">> This code should give you the desired output of a table containing the upper and lower CIs for the mean RT for each participant.\n",
    "\n",
    "If you move your cursor over the code that Copilot generated, you will see a `Copy` button appear. Clicking this will copy the code to your clipboard, so you can paste it into your notebook. We'll run this code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Upper CI  Lower CI\n",
      "participantID                    \n",
      "s1             0.430626  0.348470\n",
      "s2             0.496197  0.393373\n",
      "s3             0.515907  0.376111\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# calculate mean and standard error of the mean for each participant\n",
    "mean_rt = df.groupby('participantID')['RT'].mean()\n",
    "sem_rt = df.groupby('participantID')['RT'].sem()\n",
    "\n",
    "# calculate 95% confidence intervals for the mean RT\n",
    "ci_rt = sem_rt * 1.96\n",
    "\n",
    "# calculate upper and lower CIs\n",
    "upper_ci = mean_rt + ci_rt\n",
    "lower_ci = mean_rt - ci_rt\n",
    "\n",
    "# create a table of the upper and lower CIs\n",
    "ci_table = pd.DataFrame({'Upper CI': upper_ci, 'Lower CI': lower_ci})\n",
    "\n",
    "# print the table of CIs\n",
    "print(ci_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, this is great progress. We now have our output in a table with both upper and lower CIs, and we can see that the CIs are in the range we would expect. It wouldn't hurt to cross-check the formula that Copilot is using against a textbook or online resource."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Check Copilot's Code with Other Sources\n",
    "\n",
    "Consistent results from a number of top hits on a Web search for `confidence interval formula` indicate that the formula for calculating the 95% CI for the mean is:\n",
    "\n",
    "```python\n",
    "ci_upper = mean + 1.96 * (std / sqrt(n))\n",
    "ci_lower = mean - 1.96 * (std / sqrt(n))\n",
    "```\n",
    "\n",
    "where `mean` is the mean of the data, `std` is the standard deviation of the data, and `n` is the number of observations.\n",
    "\n",
    "However, Copilot's code multiplied 1.96 by `sem_rt`, which is the standard error of the mean. But if you look up the formula for standard error, you will find that it is the standard deviation of the data divided by the square root of the number of observations. So, Copilot's code is correct, but it's using a different formula than the one I found online. But at least now we can be confident that the code is doing what we want it to do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carrying On – STOPPED HERE\n",
    "\n",
    "Let's use the same approach for the next step, calculating 95% CIs across all participants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'rt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/mambaforge/envs/ncil/lib/python3.10/site-packages/pandas/core/indexes/base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/mambaforge/envs/ncil/lib/python3.10/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/mambaforge/envs/ncil/lib/python3.10/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'rt'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# calculate 95% confidence intervals across participantid\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df[\u001b[39m'\u001b[39;49m\u001b[39mrt\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mmean() \u001b[39m+\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mrt\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39msem() \u001b[39m*\u001b[39m \u001b[39m1.96\u001b[39m\n",
      "File \u001b[0;32m~/mambaforge/envs/ncil/lib/python3.10/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3762\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/mambaforge/envs/ncil/lib/python3.10/site-packages/pandas/core/indexes/base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3655\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3656\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3657\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3660\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'rt'"
     ]
    }
   ],
   "source": [
    "# calculate 95% confidence intervals across participantid\n",
    "df['rt'].mean() + df['rt'].sem() * 1.96\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're back to the `rt` Key Error we saw before, which was due to the case-sensitivity of Python. We can fix it manually, or think about how to make our prompts more precise, to reduce the chance of Copilot making this error. Let's try the latter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45911120518780957"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate 95% confidence intervals for RT across participantid\n",
    "df['RT'].mean() + df['RT'].sem() * 1.96"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So yes, by explicitly providing the correctly-capitalized name of the column we want, we can avoid the error. But we can also see that Copilot is not very good at understanding our prompts in the specific context of the notebook file or active kernel that we're working in. It would be nice if Copilot were more sensitive to the names of variables that are actually defined in our kernel, and that will probably come in the future. But for now, we need to be careful about how we write our prompts, to be as explicit as we can about what we actually want. Often this requires you to think a bit more deeply about the structure of your data, and what you want to do with it, and be more *precise* in the phrasing of your prompts. Over time, developing this skill leads to better critical and analytical thinking, and makes you a better data scientist.\n",
    "\n",
    "## Formatting the output nicely\n",
    "\n",
    "The next instruction is to \"Print all of the above results to the screen, rounded to 2 decimal places and with accompanying text that indicates what each result is. Be sure that it is clear that RT is in seconds.\". In a typical workflow, we might want to get each of the above calculations working correctly, and then modify the code in those cells further to get nice-looking output. However, for explanatory purposes we will keep the above ones as they are, and copy the working prompts from above so that we can add instructions for formatting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "participantID\n",
       "s1    trial    5.50\\nRT       0.39\\nName: s1, dtype:...\n",
       "s2    trial    5.50\\nRT       0.44\\nName: s2, dtype:...\n",
       "s3    trial    5.50\\nRT       0.45\\nName: s3, dtype:...\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate mean RT for each participantid rounded to 2 decimal places\n",
    "# and provide accompanying text that indicates what each result is,\n",
    "# and that RT is in seconds\n",
    "df.groupby('participantID').mean().round(2).apply(lambda x: str(x) + ' seconds', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems almost right, but there are weird extra characters in there: `\\n`. As well, it is outputting the means for both `RT` and `trial`, even though we only asked for `RT`. \n",
    "\n",
    "At this point, we could try to fix this ourselves, which would involve some Web searching to first understand what this line of code is actually doing (if you're not already familiar with the extended chain of methods and functions in this complex command), and then figuring out how to generate better output. But again, we can use Copilot to expedite this process. \n",
    "\n",
    "![](images/chat_icon.png) Click again on the Copilot Chat icon in the Activity Bar. Let's first ask for an explanation of the code. This is a complex line of code with four operations chained together, including an embedded `lambda()` function, which we haven't learned about yet. \n",
    "\n",
    "To get an explanation of the code, I first selected the entire line of code with muy curor. Then, in the Copilot Chat window, I typed `explain the highlighted line of code`. In response, I got the following explanation:\n",
    "\n",
    ">The highlighted line of code calculates the mean of all numerical columns in the dataframe `df` for each unique value in the 'participantID' column. The resulting dataframe contains the mean for each numerical column, with the index being the unique values in the 'participantID' column.\n",
    ">\n",
    ">The `groupby()` method is used to group the data by the 'participantID' column, and the `mean()` method is used to calculate the mean for each group. The resulting dataframe contains the mean for each numerical column, with the index being the unique values in the 'participantID' column.\n",
    ">\n",
    ">The `round()` method is used to round the mean values to two decimal places, and the `apply()` method is used to add the string ' seconds' to each value in the dataframe. The `axis=1` parameter specifies that the function should be applied to each row of the dataframe.\n",
    ">\n",
    ">This code is useful when working with data that has multiple participants and you want to calculate summary statistics for each participant. By using the `groupby()` method, you can easily calculate summary statistics for each group without having to manually subset the data.\n",
    ">\n",
    ">The resulting dataframe can be used to create a summary table or plot of the mean values for each participant. The `apply()` method can be modified to add different strings or formatting to the mean values, depending on the desired output.\n",
    "\n",
    "This is a good explanation of what the code is doing. But it doesn't provide a lot of insight into why the formatting is off, or why `trial` is included. So let's try asking Copilot a more specific question about the things we don't like about the code. I tried this prompt: `This seems almost right, but there are weird extra characters in there: `\\n`. As well, it is outputting the means for both `RT` and `trial`, even though we only asked for `RT`. \n",
    "\n",
    "At this point, we could try to fix this ourselves, which would involve some Web searching to first understand what this line of code is actually doing (if you're not already familiar with the extended chain of methods and functions in this complex command), and then figuring out how to generate better output. But again, we can use Copilot to expedite this process. \n",
    "\n",
    "![](images/chat_icon.png) Click again on the Copilot Chat icon in the Activity Bar. Let's first ask for an explanation of the code. This is a complex line of code with four operations chained together, including an embedded `lambda()` function, which we haven't learned about yet. \n",
    "\n",
    "To get an explanation of the code, I first selected the entire line of code with muy curor. Then, in the Copilot Chat window, I typed `explain the highlighted line of code`. In response, I got the following explanation:\n",
    "\n",
    ">The highlighted line of code calculates the mean of all numerical columns in the dataframe `df` for each unique value in the 'participantID' column. The resulting dataframe contains the mean for each numerical column, with the index being the unique values in the 'participantID' column.\n",
    ">\n",
    ">The `groupby()` method is used to group the data by the 'participantID' column, and the `mean()` method is used to calculate the mean for each group. The resulting dataframe contains the mean for each numerical column, with the index being the unique values in the 'participantID' column.\n",
    ">\n",
    ">The `round()` method is used to round the mean values to two decimal places, and the `apply()` method is used to add the string ' seconds' to each value in the dataframe. The `axis=1` parameter specifies that the function should be applied to each row of the dataframe.\n",
    ">\n",
    ">This code is useful when working with data that has multiple participants and you want to calculate summary statistics for each participant. By using the `groupby()` method, you can easily calculate summary statistics for each group without having to manually subset the data.\n",
    ">\n",
    ">The resulting dataframe can be used to create a summary table or plot of the mean values for each participant. The `apply()` method can be modified to add different strings or formatting to the mean values, depending on the desired output.\n",
    "\n",
    "This is a good explanation of what the code is doing. But it doesn't provide a lot of insight into why the formatting is off, or why `trial` is included. So let's try asking Copilot a more specific question about the things we don't like about the code. I tried this prompt: `the highlighted code prints meants for both trial and RT, but I want it to only print the mean RT for each participantid. suggest code to do what I want`. In response, I got the following:\n",
    "\n",
    ">To print only the mean RT for each participantID, you can modify the existing code to select only the 'RT' column before calling the `groupby()` and `mean()` methods. Here's an example:\n",
    ">\n",
    "\n",
    "```{python}\n",
    "df.groupby('participantID')['RT'].mean().round(2).apply(lambda x: str(x) + ' seconds')\n",
    "```\n",
    "\n",
    ">\n",
    ">In this code, the `groupby()` method is used to group the data by the 'participantID' column, and the `mean()` method is used to calculate the mean of the 'RT' column for each group. The resulting dataframe contains the mean RT for each unique value in the 'participantID' column.\n",
    ">\n",
    ">The `round()` method is used to round the mean values to two decimal places, and the `apply()` method is used to add the string ' seconds' to each value in the dataframe. The resulting series contains the mean RT for each unique value in the 'participantID' column, with the index being the unique values in the 'participantID' column.\n",
    ">\n",
    ">This code should give you the desired output of only the mean RT for each participantID, rounded to two decimal places and with the string ' seconds' added to each value.`. In response, I got the following:\n",
    "\n",
    "\n",
    ">To print only the mean RT for each participantID, you can modify the existing code to select only the 'RT' column before calling the `groupby()` and `mean()` methods. Here's an example:\n",
    ">\n",
    "\n",
    "```{python}\n",
    "df.groupby('participantID')['RT'].mean().round(2).apply(lambda x: str(x) + ' seconds')\n",
    "```\n",
    "\n",
    ">\n",
    ">In this code, the `groupby()` method is used to group the data by the 'participantID' column, and the `mean()` method is used to calculate the mean of the 'RT' column for each group. The resulting dataframe contains the mean RT for each unique value in the 'participantID' column.\n",
    ">\n",
    ">The `round()` method is used to round the mean values to two decimal places, and the `apply()` method is used to add the string ' seconds' to each value in the dataframe. The resulting series contains the mean RT for each unique value in the 'participantID' column, with the index being the unique values in the 'participantID' column.\n",
    ">\n",
    ">This code should give you the desired output of only the mean RT for each participantID, rounded to two decimal places and with the string ' seconds' added to each value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try that suggested code and see what we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "participantID\n",
       "s1    0.39 seconds\n",
       "s2    0.44 seconds\n",
       "s3    0.45 seconds\n",
       "Name: RT, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('participantID')['RT'].mean().round(2).apply(lambda x: str(x) + ' seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is great - now we have exactly what we want, and the code is even conveniently telling use that the units are seconds.\n",
    "\n",
    "Next we want to print the mean across all participants, formatted as above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.float64' object has no attribute 'apply'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# calculate mean RT across participantid rounded to 2 decimal places\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# and provide accompanying text that indicates what each result is,\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# and that RT is in seconds\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m df[\u001b[39m'\u001b[39;49m\u001b[39mRT\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mmean()\u001b[39m.\u001b[39;49mround(\u001b[39m2\u001b[39;49m)\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;00m x: \u001b[39mstr\u001b[39m(x) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m seconds\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.float64' object has no attribute 'apply'"
     ]
    }
   ],
   "source": [
    "# calculate mean RT across participantid rounded to 2 decimal places\n",
    "# and provide accompanying text that indicates what each result is,\n",
    "# and that RT is in seconds\n",
    "df['RT'].mean().round(2).apply(lambda x: str(x) + ' seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried right-clicking, gooing to Copilot, and then selecting `Fix This`. This generated the following code:\n",
    "\n",
    "```{python}\n",
    "# calculate mean RT across participantid rounded to 2 decimal places\n",
    "# and provide accompanying text that indicates what each result is,\n",
    "# and that RT is in seconds\n",
    "mean_rt = df.groupby('participantid')['RT'].mean().mean().round(2)\n",
    "result_text = str(mean_rt) + ' seconds is the mean RT across participantid'\n",
    "result_text\n",
    "result_text = str(mean_rt) + ' seconds is the mean RT across participantid'\n",
    "result_text\n",
    "```\n",
    "\n",
    "This reflects a phenomenon that seems to happen regularly with Copilot, which is that it repeats itself. Note that the last two lines of code are identical to the two lines before them. This is a bit annoying, but it's not a big deal. We can just delete the last two lines of code, and we're good to go.\n",
    "\n",
    "Also, look closely at the code: there's another bug! This time, Copilot has made a mistake in the code it generated. It's trying to group by `participantid`, but the column name is actually `participantID`. AGain, you need to be paying close attention to the code, and details like capitalization. In this case, I was being sloppy with capitalization in my prompts. Even though I already realized that I had to use `RT` and not `rt`, Copilot initially let me get away with lazily typing `participantid` and not `participantID`. But now it's come back to bite me.\n",
    "\n",
    "Since I think I understand where the error is coming from, it's more expedient to fix it myself, so I copy and paste the code from above, and then edit it to capitalize `ID`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.43 seconds is the mean RT across participantID'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate mean RT across participantid rounded to 2 decimal places\n",
    "# and provide accompanying text that indicates what each result is,\n",
    "# and that RT is in seconds\n",
    "mean_rt = df.groupby('participantID')['RT'].mean().mean().round(2)\n",
    "result_text = str(mean_rt) + ' seconds is the mean RT across participantID'\n",
    "result_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that that is fixed, let's move on to the next step, which is to calculate the 95% confidence intervals for the mean RT for each participant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "participantID\n",
       "s1    5.01 seconds\n",
       "s2    4.95 seconds\n",
       "s3    4.95 seconds\n",
       "dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate 95% confidence intervals for each participantid rounded to 2 decimal places\n",
    "# and provide accompanying text that indicates what each result is,\n",
    "# and that RT is in seconds\n",
    "df.groupby('participantID').mean().apply(lambda x: x.sem() * 1.96, axis=1).round(2).apply(lambda x: str(x) + ' seconds')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed there are! You can fix all of them at once with VS Code, by double-clicking on any instance of `subject` so that it's highlighted, and then right-clicking and choosing `Change All Occurrences`. All instances of the selected text will be highlighted, and if you start typing the replacement you want, it will replace it in every highlighted location. Alternatively, you can use the `Replace` option in the `Edit` menu to search and replace any text in the cell that is currently selected.\n",
    "\n",
    "In practice you could modify the cell and re-run it, but for the flow of this exercise, we'll just run the cell below that has the repaired variable name, and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mean rt for each participantID\n",
    "df.groupby('participantID').mean()\n",
    "\n",
    "# calculate mean rt across participantIDs\n",
    "df.groupby('participantID').mean().mean()\n",
    "\n",
    "# calculate 95% confidence intervals for each participantID\n",
    "df.groupby('participantID').mean().sem() * 1.96\n",
    "\n",
    "# calculate 95% confidence intervals across participantIDs\n",
    "df.groupby('participantID').mean().mean().sem() * 1.96\n",
    "\n",
    "# print all of the above results in a nice format\n",
    "print('Mean RT for each participantID:')\n",
    "print(df.groupby('participantID').mean())\n",
    "print('\\nMean RT across participantIDs:')\n",
    "print(df.groupby('participantID').mean().mean())\n",
    "print('\\n95% confidence intervals for each participantID:')\n",
    "print(df.groupby('participantID').mean().sem() * 1.96)\n",
    "print('\\n95% confidence intervals across participantIDs:')\n",
    "print(df.groupby('participantID').mean().mean().sem() * 1.96)\n",
    "\n",
    "# plots mean RT across subjects, with 95% confidence intervals\n",
    "df.groupby('participantID').mean().plot(yerr=df.groupby('participantID').mean().sem() * 1.96)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Copilot Did\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fix the code to only show the mean RT, you need to modify the code to only select the 'rt' column before calculating the mean. You can do this by changing the first line of code to:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rt'].groupby(df['participantID']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "This code selects only the 'rt' column using the indexing operator and then groups the data by 'participantID' before calculating the mean. This will give you the mean RT for each participantID.\n",
    "\n",
    "You can then modify the rest of the code to use this new dataframe. Here is the modified code:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mean rt for each participantID\n",
    "mean_rt = df['rt'].groupby(df['participantID']).mean()\n",
    "\n",
    "# calculate mean rt across participantIDs\n",
    "mean_rt_all = mean_rt.mean()\n",
    "\n",
    "# calculate 95% confidence intervals for each participantID\n",
    "ci_rt = mean_rt.sem() * 1.96\n",
    "\n",
    "# calculate 95% confidence intervals across participantIDs\n",
    "ci_rt_all = mean_rt_all.sem() * 1.96\n",
    "\n",
    "# print all of the above results in a nice format\n",
    "print('Mean RT for each participantID:')\n",
    "print(mean_rt)\n",
    "print('\\nMean RT across participantIDs:')\n",
    "print(mean_rt_all)\n",
    "print('\\n95% confidence intervals for each participantID:')\n",
    "print(ci_rt)\n",
    "print('\\n95% confidence intervals across participantIDs:')\n",
    "print(ci_rt_all)\n",
    "\n",
    "# plots mean RT across subjects, with 95% confidence intervals\n",
    "mean_rt.plot(yerr=ci_rt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "This code will now only calculate the mean RT and will print and plot the results accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mean rt for each participantID\n",
    "mean_rt = df['rt'].groupby(df['participantID']).mean()\n",
    "\n",
    "# calculate mean rt across participantIDs\n",
    "mean_rt_all = mean_rt.mean()\n",
    "\n",
    "# calculate 95% confidence intervals for each participantID\n",
    "ci_rt = mean_rt.sem() * 1.96\n",
    "\n",
    "# calculate 95% confidence intervals across participantIDs\n",
    "ci_rt_all = mean_rt_all.sem() * 1.96\n",
    "\n",
    "# print all of the above results in a nice format\n",
    "print('Mean RT for each participantID:')\n",
    "print(mean_rt)\n",
    "print('\\nMean RT across participantIDs:')\n",
    "print(mean_rt_all)\n",
    "print('\\n95% confidence intervals for each participantID:')\n",
    "print(ci_rt)\n",
    "print('\\n95% confidence intervals across participantIDs:')\n",
    "print(ci_rt_all)\n",
    "\n",
    "# plots mean RT across subjects, with 95% confidence intervals\n",
    "mean_rt.plot(yerr=ci_rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above does most of what we want, but it does generate another message – this time a warning, not an error. Warnings are worth looking at as well, because they can indicate that something is not quite right. Sometimes they are things like \"deprecation notices\", which occur when a package has changed, and the old way of doing something is no longer supported. However, this warning reads, `UserWarning: Warning: converting a masked element to nan.` What does this mean? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ncil",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
