{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 5: Merging DataFrames with pandas\n",
    "\n",
    "[View this lesson on datacamp](https://learn.datacamp.com/courses/merging-dataframes-with-pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 2: Concatenating Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appending pandas Series and DataFrames\n",
    "\n",
    "The `.append()` method is used for both pandas Series and DataFrames, to stack rows on top of each other. For example, appending the two pandas Series below results in one series in which the elements of 'blue' are stacked underneath the elements of 'pink' (since we append blue to pink in this case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          rose\n",
       "1       fuchsia\n",
       "2          ruby\n",
       "3       magenta\n",
       "0     turquoise\n",
       "1      sky blue\n",
       "2          navy\n",
       "3    ocean blue\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pink = pd.Series(['rose', 'fuchsia', 'ruby', 'magenta'])\n",
    "blue = pd.Series(['turquoise', 'sky blue', 'navy', 'ocean blue'])\n",
    "pb = pink.append(blue)\n",
    "pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       rose\n",
       "1    fuchsia\n",
       "2       ruby\n",
       "3    magenta\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pink"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appending Series with nonunique indices\n",
    "\n",
    "One thing to note here is that the `.append()` method doesn't adjust the index of the series when it stacks them.  You can see this above in that the first column (which is the index) goes from zero to three, then zero to three again. This can be an issue when working with a Series or DataFrame later on, so it's a good idea to re-index.\n",
    "\n",
    "This can be done using the `.reset_index()` method, which sets the row indexes sequentially from 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>rose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>fuchsia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ruby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>magenta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>turquoise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>sky blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>navy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>ocean blue</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index           0\n",
       "0      0        rose\n",
       "1      1     fuchsia\n",
       "2      2        ruby\n",
       "3      3     magenta\n",
       "4      0   turquoise\n",
       "5      1    sky blue\n",
       "6      2        navy\n",
       "7      3  ocean blue"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pb.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll see there's a weird extra column in there now; the index is the rightmost column (in bold), and the original index is now a column called \"index\". In some cases this might be a helpful historical record, but in many cases it's just annoying. Adding the argument `drop=True` will drop the original index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          rose\n",
       "1       fuchsia\n",
       "2          ruby\n",
       "3       magenta\n",
       "4     turquoise\n",
       "5      sky blue\n",
       "6          navy\n",
       "7    ocean blue\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pb.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "One important \"gotcha\" with `.reset_index()` — and many pandas DataFrame methods — is that <b>by default they don't actually modify the Series or DataFrame you run them on</b>. \n",
    "    \n",
    "So after running the command above, you might think you reset the index of `pb`, but actually you didn't; instead you just saw the copy that was created by your command, printed as output. Thus when we ask to see `pb` again, the index is unchanged:\n",
    "</div>\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          rose\n",
       "1       fuchsia\n",
       "2          ruby\n",
       "3       magenta\n",
       "0     turquoise\n",
       "1      sky blue\n",
       "2          navy\n",
       "3    ocean blue\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So to actually reset the index of `pb`, we need to *assign* the output of the method back to `pb`, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          rose\n",
       "1       fuchsia\n",
       "2          ruby\n",
       "3       magenta\n",
       "4     turquoise\n",
       "5      sky blue\n",
       "6          navy\n",
       "7    ocean blue\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pb = pb.reset_index(drop=True)\n",
    "pb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can alternatively do this by including the `inplace=True` argument, in which case you don't need to assign the output with `pb = `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          rose\n",
       "1       fuchsia\n",
       "2          ruby\n",
       "3       magenta\n",
       "4     turquoise\n",
       "5      sky blue\n",
       "6          navy\n",
       "7    ocean blue\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pb = pink.append(blue)\n",
    "pb.reset_index(drop=True, inplace=True)\n",
    "pb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to combine pandas objects (Series or DataFrames) is concatenation. The `pd.concat()` function is a more powerful and flexible tool than the `.append()` method. Whereas appending always adds rows to the bottom of a DataFrame, concatenation can do this, *or* add columns to a DataFrame.\n",
    "\n",
    "[API for `pd.concat()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html?highlight=concat#pandas.concat)\n",
    "\n",
    "THere's also a nice, detailed explanation of appending, concatenating, merging, and joining DataFrames [here](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html)\n",
    "\n",
    "Here's how we would use `pd.concat()` to do the same thing we did above, with `.append()`. There are two major difference to pay attention to. Firstly, `pd.concat()` is a *function*, whereas `.append()` is a *method*. Recall that methods are applied by dot-adding them to the variable name you want to modify (e.g., `pink.append(blue)`). With a function, we have to specify `pd` before the dot and the function name after, and give it all the input data as the first argument inside the parentheses. It's also important to pay attention to how we specify the input data: since the functions arguments are separated by commas, you can't just list the input data like this:\n",
    "`pd.concat(pink, blue)`, because `'pink` will be interpreted as the input data, and `blue` as a second argument. We need to put the input data inside a list, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          rose\n",
       "1       fuchsia\n",
       "2          ruby\n",
       "3       magenta\n",
       "0     turquoise\n",
       "1      sky blue\n",
       "2          navy\n",
       "3    ocean blue\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pb = pd.concat([pink, blue])\n",
    "pb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with `.append()`, the original index values are preserved, which we might not want. While with `.append()` we had to run a separate method to reset the index, with `pd.concat()` we can do this at the same time as the concatenation, using the `ignore_index` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          rose\n",
       "1       fuchsia\n",
       "2          ruby\n",
       "3       magenta\n",
       "4     turquoise\n",
       "5      sky blue\n",
       "6          navy\n",
       "7    ocean blue\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pb = pd.concat([pink, blue], ignore_index=True)\n",
    "pb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `.append()` and `pd.concat()` on DataFrames\n",
    "\n",
    "Above we were working with pandas Series. For pandas DataFrames, the append method works just the same, stacking the rows. \n",
    "\n",
    "Here we will use what we learned in chapter 1 to read two CSV files as DataFrames, then combine them with the `append()` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trial</th>\n",
       "      <th>RT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.508971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.389858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.404175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.269520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.437765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.368142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.400544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.335198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.341722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.439583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.433094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.392526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.396831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.417988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.371810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.659228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.411051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.409580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.486828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.468912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trial        RT\n",
       "0      1  0.508971\n",
       "1      2  0.389858\n",
       "2      3  0.404175\n",
       "3      4  0.269520\n",
       "4      5  0.437765\n",
       "5      6  0.368142\n",
       "6      7  0.400544\n",
       "7      8  0.335198\n",
       "8      9  0.341722\n",
       "9     10  0.439583\n",
       "0      1  0.433094\n",
       "1      2  0.392526\n",
       "2      3  0.396831\n",
       "3      4  0.417988\n",
       "4      5  0.371810\n",
       "5      6  0.659228\n",
       "6      7  0.411051\n",
       "7      8  0.409580\n",
       "8      9  0.486828\n",
       "9     10  0.468912"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = pd.read_csv('s1.csv')\n",
    "s2 = pd.read_csv('s2.csv')\n",
    "\n",
    "all_data = s1.append(s2)\n",
    "\n",
    "all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Appending DataFrames with ignore_index\n",
    "\n",
    "We can also do this with `pd.concat()`, again using `ignore_index=True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trial</th>\n",
       "      <th>RT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.508971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.389858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.404175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.269520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.437765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.368142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.400544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.335198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.341722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.439583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0.433094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>0.392526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>0.396831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>0.417988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>0.371810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6</td>\n",
       "      <td>0.659228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7</td>\n",
       "      <td>0.411051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8</td>\n",
       "      <td>0.409580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9</td>\n",
       "      <td>0.486828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10</td>\n",
       "      <td>0.468912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    trial        RT\n",
       "0       1  0.508971\n",
       "1       2  0.389858\n",
       "2       3  0.404175\n",
       "3       4  0.269520\n",
       "4       5  0.437765\n",
       "5       6  0.368142\n",
       "6       7  0.400544\n",
       "7       8  0.335198\n",
       "8       9  0.341722\n",
       "9      10  0.439583\n",
       "10      1  0.433094\n",
       "11      2  0.392526\n",
       "12      3  0.396831\n",
       "13      4  0.417988\n",
       "14      5  0.371810\n",
       "15      6  0.659228\n",
       "16      7  0.411051\n",
       "17      8  0.409580\n",
       "18      9  0.486828\n",
       "19     10  0.468912"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# s1 and s2 are already loaded into memory from above\n",
    "\n",
    "df = pd.concat([s1, s2], ignore_index=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading multiple files to build a DataFrame\n",
    "\n",
    "We can get a bit more fancy and use a loop to read in files, as in the previous chapter, and then combine them. Here's the code from the last chapter, which reads the CSV files in to a list of DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = ['s1.csv', 's2.csv', 's3.csv']\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for filename in filenames:\n",
    "    df_list.append(pd.read_csv(filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since `df_list` is already a list — which is the format that `pdconcat()` wants its input in — we can just pass the whole thing to `pd.concat()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trial</th>\n",
       "      <th>RT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.508971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.389858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.404175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.269520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.437765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.368142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.400544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.335198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.341722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.439583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0.433094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>0.392526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>0.396831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>0.417988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>0.371810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6</td>\n",
       "      <td>0.659228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7</td>\n",
       "      <td>0.411051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8</td>\n",
       "      <td>0.409580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9</td>\n",
       "      <td>0.486828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10</td>\n",
       "      <td>0.468912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>0.322099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>0.396106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3</td>\n",
       "      <td>0.384297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4</td>\n",
       "      <td>0.364524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5</td>\n",
       "      <td>0.454075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6</td>\n",
       "      <td>0.494156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7</td>\n",
       "      <td>0.492787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>8</td>\n",
       "      <td>0.506836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>9</td>\n",
       "      <td>0.340722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>10</td>\n",
       "      <td>0.704491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    trial        RT\n",
       "0       1  0.508971\n",
       "1       2  0.389858\n",
       "2       3  0.404175\n",
       "3       4  0.269520\n",
       "4       5  0.437765\n",
       "5       6  0.368142\n",
       "6       7  0.400544\n",
       "7       8  0.335198\n",
       "8       9  0.341722\n",
       "9      10  0.439583\n",
       "10      1  0.433094\n",
       "11      2  0.392526\n",
       "12      3  0.396831\n",
       "13      4  0.417988\n",
       "14      5  0.371810\n",
       "15      6  0.659228\n",
       "16      7  0.411051\n",
       "17      8  0.409580\n",
       "18      9  0.486828\n",
       "19     10  0.468912\n",
       "20      1  0.322099\n",
       "21      2  0.396106\n",
       "22      3  0.384297\n",
       "23      4  0.364524\n",
       "24      5  0.454075\n",
       "25      6  0.494156\n",
       "26      7  0.492787\n",
       "27      8  0.506836\n",
       "28      9  0.340722\n",
       "29     10  0.704491"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenating columns rather than rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As noted earlier, `pd.concat()` is more powerful in how it combine inputs. \n",
    "\n",
    "Consider this example, where we have different data about the same participants, in different files. One file contains participants' birthday month, and the other their age. What we want is to end up with a DataFrame with one row per participant, with columns for participant number, `Fav Color` and `Brithday Month`. However, when we read in the two input files and concatenate them, we get a column for colour and a column for month, with lots of NaN values in each because each input file had different column names, but we've stacked the rows of the inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant num</th>\n",
       "      <th>Fav Colour</th>\n",
       "      <th>Birthday Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>blue</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>red</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>green</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>purple</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>green</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>orange</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>yellow</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>yellow</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>pink</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>may</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>june</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>january</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>february</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>september</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>july</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>may</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>may</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>august</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>december</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Participant num Fav Colour Birthday Month\n",
       "0                1       blue            NaN\n",
       "1                2        red            NaN\n",
       "2                3      green            NaN\n",
       "3                4    purple             NaN\n",
       "4                5        red            NaN\n",
       "5                6      green            NaN\n",
       "6                7     orange            NaN\n",
       "7                8    yellow             NaN\n",
       "8                9    yellow             NaN\n",
       "9               10       pink            NaN\n",
       "0                1        NaN           may \n",
       "1                2        NaN          june \n",
       "2                3        NaN        january\n",
       "3                4        NaN      february \n",
       "4                5        NaN     september \n",
       "5                6        NaN          july \n",
       "6                7        NaN           may \n",
       "7                8        NaN           may \n",
       "8                9        NaN         august\n",
       "9               10        NaN       december"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fav_colour = pd.read_csv('fav_colour.csv')\n",
    "birthday_month = pd.read_csv('birthday_months.csv')\n",
    "\n",
    "df = pd.concat([fav_colour, birthday_month])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see above that there's also a `participant num` column, which indicates how we can match colours to months. What we actually want is to combine the two inputs \"horizontally\", such that we have 10 rows (one for each participant), with the colour and month corresponding to each participant in the same row. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default when concatenating dataframes is to do so vertically, as we saw above. However, `pd.concat()` allows us to concatenate horizontally as well. To do this, you must specify either `axis=1`, or `axis=columns`. Note in the example below, the rows with identical indices get combined when concatenated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant num</th>\n",
       "      <th>Fav Colour</th>\n",
       "      <th>Participant num</th>\n",
       "      <th>Birthday Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>blue</td>\n",
       "      <td>1</td>\n",
       "      <td>may</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>red</td>\n",
       "      <td>2</td>\n",
       "      <td>june</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>green</td>\n",
       "      <td>3</td>\n",
       "      <td>january</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>purple</td>\n",
       "      <td>4</td>\n",
       "      <td>february</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "      <td>5</td>\n",
       "      <td>september</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>green</td>\n",
       "      <td>6</td>\n",
       "      <td>july</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>orange</td>\n",
       "      <td>7</td>\n",
       "      <td>may</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>yellow</td>\n",
       "      <td>8</td>\n",
       "      <td>may</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>yellow</td>\n",
       "      <td>9</td>\n",
       "      <td>august</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>pink</td>\n",
       "      <td>10</td>\n",
       "      <td>december</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Participant num Fav Colour  Participant num Birthday Month\n",
       "0                1       blue                1           may \n",
       "1                2        red                2          june \n",
       "2                3      green                3        january\n",
       "3                4    purple                 4      february \n",
       "4                5        red                5     september \n",
       "5                6      green                6          july \n",
       "6                7     orange                7           may \n",
       "7                8    yellow                 8           may \n",
       "8                9    yellow                 9         august\n",
       "9               10       pink               10       december"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([fav_colour, birthday_month], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're still not quite where we want to be, as we have two redundant `Participant num` columns. When concatenating, pandas plays it safe, and doesn't assume that two columns with the same name are redundant. One way to fix this is, when we load the data in the beginning, we make the index of each input DataFrame the `participant num` column. Since indexes are essentially row labels, making participant_num the index tells pandas that indeed, these two columns with the same name are actually the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fav Colour</th>\n",
       "      <th>Birthday Month</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Participant num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blue</td>\n",
       "      <td>may</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>red</td>\n",
       "      <td>june</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>green</td>\n",
       "      <td>january</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>purple</td>\n",
       "      <td>february</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>red</td>\n",
       "      <td>september</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>green</td>\n",
       "      <td>july</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>orange</td>\n",
       "      <td>may</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>yellow</td>\n",
       "      <td>may</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>yellow</td>\n",
       "      <td>august</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pink</td>\n",
       "      <td>december</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Fav Colour Birthday Month\n",
       "Participant num                          \n",
       "1                     blue           may \n",
       "2                      red          june \n",
       "3                    green        january\n",
       "4                  purple       february \n",
       "5                      red     september \n",
       "6                    green          july \n",
       "7                   orange           may \n",
       "8                  yellow            may \n",
       "9                  yellow          august\n",
       "10                    pink       december"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fav_colour = pd.read_csv('fav_colour.csv', index_col='Participant num')\n",
    "birthday_month = pd.read_csv('birthday_months.csv', index_col='Participant num')\n",
    "\n",
    "df = pd.concat([fav_colour, birthday_month], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we could make one of the `Participant num` columns the index after concatenation, but specifying the index when we read in the data is a safer way of doing things. This is because, it could happen that your data aren't in the same order in both data files (e.g., one data file might not be sorted by `Participant num`), or one file might have missing data. By making `Participant num` the index for each file before we concatenate them, we ensure that pandas matches the rows from each input based on its index. \n",
    "\n",
    "Importantly, this is a case where we would *not* want to include the `ignore_index=True` argument to `pd.concat()`, because the index is important and meaningful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultiIndexes\n",
    "\n",
    "MultiIndexes extend pandas indesing, allowing you to designate multiple columns as indexes. For example, you may have data for each month of the year, from multiple years. In this case, you might want to use month as the index, but you would not want pandas to treat January, 2019, as the same as January, 2020. You you would want indexes both for month, and for year.\n",
    "\n",
    "MultiIndexes can be applied to both rows (for which we've already learned about single-indexing), and to columns. \n",
    "\n",
    "Imagine we collected reaction time (RT) data from an individual human participant in two different testing sessions. Each session involved 10 experimental trials. Between the first and the second session, the person played cognitive training games and we want to know if their RTs decreased due to the training. So we can load in the two data files (one from each session):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess_1 = pd.read_csv('session_1.csv', index_col='trial')\n",
    "sess_2 = pd.read_csv('session_2.csv', index_col='trial')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we view the data from each session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trial</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          rt\n",
       "trial       \n",
       "0      0.988\n",
       "1      0.753\n",
       "2      0.949\n",
       "3      0.824\n",
       "4      0.262\n",
       "5      0.803\n",
       "6      0.376\n",
       "7      0.496\n",
       "8      0.235\n",
       "9      0.336\n",
       "10     0.645"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trial</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          rt\n",
       "trial       \n",
       "0      0.718\n",
       "1      0.851\n",
       "2      0.747\n",
       "3      0.520\n",
       "4      0.991\n",
       "5      0.004\n",
       "6      0.547\n",
       "7      0.883\n",
       "8      0.841\n",
       "9      0.195\n",
       "10     0.828"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that because of the `index_col='trial'` argument to `pd_read_csv()`, trial number is used as the index for each DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can concatenate the data. One way to do this is simply appending the rows of `sess_2` to the bottom of `sess_1`, and use the `axis=0` argument to specify conctenation is by rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trial</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          rt\n",
       "trial       \n",
       "0      0.988\n",
       "1      0.753\n",
       "2      0.949\n",
       "3      0.824\n",
       "4      0.262\n",
       "5      0.803\n",
       "6      0.376\n",
       "7      0.496\n",
       "8      0.235\n",
       "9      0.336\n",
       "10     0.645\n",
       "0      0.718\n",
       "1      0.851\n",
       "2      0.747\n",
       "3      0.520\n",
       "4      0.991\n",
       "5      0.004\n",
       "6      0.547\n",
       "7      0.883\n",
       "8      0.841\n",
       "9      0.195\n",
       "10     0.828"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess_12 = pd.concat([sess_1, sess_2], axis=0)\n",
    "sess_12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem with the result above is that we don't know which session each data point came from. We know session names from the names of the files, but that information doesn't get used in making the DataFrame. We can deal with this by manually specifying the session names, and using them as row indexes. Critically, we will use MultiIndexing so that `trial` is retained as an index. In other words, there are two indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>rt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>trial</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">sess_1</th>\n",
       "      <th>0</th>\n",
       "      <td>0.988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">sess_2</th>\n",
       "      <th>0</th>\n",
       "      <td>0.718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 rt\n",
       "       trial       \n",
       "sess_1 0      0.988\n",
       "       1      0.753\n",
       "       2      0.949\n",
       "       3      0.824\n",
       "       4      0.262\n",
       "       5      0.803\n",
       "       6      0.376\n",
       "       7      0.496\n",
       "       8      0.235\n",
       "       9      0.336\n",
       "       10     0.645\n",
       "sess_2 0      0.718\n",
       "       1      0.851\n",
       "       2      0.747\n",
       "       3      0.520\n",
       "       4      0.991\n",
       "       5      0.004\n",
       "       6      0.547\n",
       "       7      0.883\n",
       "       8      0.841\n",
       "       9      0.195\n",
       "       10     0.828"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess_12 = pd.concat([sess_1, sess_2], keys=['sess_1', 'sess_2'], axis=0)\n",
    "sess_12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can the use the `.loc[]` property to select all trials from one session or the other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trial</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          rt\n",
       "trial       \n",
       "0      0.988\n",
       "1      0.753\n",
       "2      0.949\n",
       "3      0.824\n",
       "4      0.262\n",
       "5      0.803\n",
       "6      0.376\n",
       "7      0.496\n",
       "8      0.235\n",
       "9      0.336\n",
       "10     0.645"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess_12.loc['sess_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenating DataFrames from a dict\n",
    "\n",
    "Instead of using the `keys=[]` argument to `pd.concat()`, we can create a dictionary mapping index labels to input DataFrames. This works just as well as using the `keys` argument, but it's a little safer and more explicit, because with a dictionary the mapping between labels and data is easy to verify. Using separate lists of DataFrames and keys relies on ensuring that the order of items is the same in both lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>rt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>trial</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">session 1</th>\n",
       "      <th>0</th>\n",
       "      <td>0.988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">session 2</th>\n",
       "      <th>0</th>\n",
       "      <td>0.718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    rt\n",
       "          trial       \n",
       "session 1 0      0.988\n",
       "          1      0.753\n",
       "          2      0.949\n",
       "          3      0.824\n",
       "          4      0.262\n",
       "          5      0.803\n",
       "          6      0.376\n",
       "          7      0.496\n",
       "          8      0.235\n",
       "          9      0.336\n",
       "          10     0.645\n",
       "session 2 0      0.718\n",
       "          1      0.851\n",
       "          2      0.747\n",
       "          3      0.520\n",
       "          4      0.991\n",
       "          5      0.004\n",
       "          6      0.547\n",
       "          7      0.883\n",
       "          8      0.841\n",
       "          9      0.195\n",
       "          10     0.828"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess_dict = {'session 1':sess_1, 'session 2':sess_2}\n",
    "\n",
    "sess_12 = pd.concat(sess_dict)\n",
    "\n",
    "sess_12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenating Columns\n",
    "\n",
    "We can instead concatenate the data by column, as we did earlier for colours and birthday month:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rt</th>\n",
       "      <th>rt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trial</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.988</td>\n",
       "      <td>0.718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.753</td>\n",
       "      <td>0.851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.949</td>\n",
       "      <td>0.747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.824</td>\n",
       "      <td>0.520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.262</td>\n",
       "      <td>0.991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.376</td>\n",
       "      <td>0.547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.496</td>\n",
       "      <td>0.883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.235</td>\n",
       "      <td>0.841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.336</td>\n",
       "      <td>0.195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.645</td>\n",
       "      <td>0.828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          rt     rt\n",
       "trial              \n",
       "0      0.988  0.718\n",
       "1      0.753  0.851\n",
       "2      0.949  0.747\n",
       "3      0.824  0.520\n",
       "4      0.262  0.991\n",
       "5      0.803  0.004\n",
       "6      0.376  0.547\n",
       "7      0.496  0.883\n",
       "8      0.235  0.841\n",
       "9      0.336  0.195\n",
       "10     0.645  0.828"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess_12 = pd.concat([sess_1, sess_2], axis='columns')  # We could also use axis=1\n",
    "\n",
    "sess_12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the same problem as when concatenating by row; that there are two `rt` columns and no indication of which is associated with which session. So we can use MultiIndexing on the columns - just as we did for rows above, to add the session numbers. We do this by first creating a dictionary mapping each session's data to a label, and then using that dictionary as the input to `pd.concat()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>session 1</th>\n",
       "      <th>session 2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>rt</th>\n",
       "      <th>rt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trial</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.988</td>\n",
       "      <td>0.718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.753</td>\n",
       "      <td>0.851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.949</td>\n",
       "      <td>0.747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.824</td>\n",
       "      <td>0.520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.262</td>\n",
       "      <td>0.991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.803</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.376</td>\n",
       "      <td>0.547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.496</td>\n",
       "      <td>0.883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.235</td>\n",
       "      <td>0.841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.336</td>\n",
       "      <td>0.195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.645</td>\n",
       "      <td>0.828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      session 1 session 2\n",
       "             rt        rt\n",
       "trial                    \n",
       "0         0.988     0.718\n",
       "1         0.753     0.851\n",
       "2         0.949     0.747\n",
       "3         0.824     0.520\n",
       "4         0.262     0.991\n",
       "5         0.803     0.004\n",
       "6         0.376     0.547\n",
       "7         0.496     0.883\n",
       "8         0.235     0.841\n",
       "9         0.336     0.195\n",
       "10        0.645     0.828"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess_dict = {'session 1':sess_1, 'session 2':sess_2}\n",
    "sess_12 = pd.concat(sess_dict, axis='columns')\n",
    "\n",
    "sess_12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the original column labels (`rt`) are preserved but above these are unique labels for each session.\n",
    "\n",
    "#### Selecting and slicing on MultiIndexes\n",
    "\n",
    "When we had row MultiIndexes above, we used `.loc` to access specific data, like for one session. However, `.loc` operates on rows, not columns, so we can't use it to select data from one session in this case. There are a few ways we can access MultiIndexes with columns, but one of the most intuitive to use is via the function `pd.IndexSlice`. This allows you to use `.loc` with a [*rows*, *columns*] syntax, as shown below, where we select all rows with `:` and the specific column by specifying its label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trial</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          rt\n",
       "trial       \n",
       "0      0.988\n",
       "1      0.753\n",
       "2      0.949\n",
       "3      0.824\n",
       "4      0.262\n",
       "5      0.803\n",
       "6      0.376\n",
       "7      0.496\n",
       "8      0.235\n",
       "9      0.336\n",
       "10     0.645"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess_12.loc[pd.IndexSlice[:,'session 1']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also select only some trials from one session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trial</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          rt\n",
       "trial       \n",
       "0      0.988\n",
       "1      0.753\n",
       "2      0.949\n",
       "3      0.824"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess_12.loc[pd.IndexSlice[0:3, 'session 1']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One trick that you will often see (including in DataCamp) is to assign `pd.IndexSlice` to a shorter variable name, typically `idx`. This can make your commands a little simpler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trial</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          rt\n",
       "trial       \n",
       "0      0.988\n",
       "1      0.753\n",
       "2      0.949\n",
       "3      0.824\n",
       "4      0.262\n",
       "5      0.803\n",
       "6      0.376\n",
       "7      0.496\n",
       "8      0.235\n",
       "9      0.336\n",
       "10     0.645"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = pd.IndexSlice\n",
    "\n",
    "sess_12.loc[idx[:,'session 1']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outer and Inner Joins \n",
    "\n",
    "\"Joins\" refer to how two DataFrames are combined. \n",
    "\n",
    "To demonstrate, we'll start by showing how this works with NumPy arrays, and then move on to how to do the same things with pandas DataFrames. \n",
    "\n",
    "#### NumPy\n",
    "\n",
    "For NumPy, the first step is to create three NumPy arrays, each with different dimensions. To do this we use NumPy's `random.rand()` function, which creates an array with a specified shape, filled with random numbers. We *chain* this with the `.round()` method to shorten the numbers, then multiply the array by 100 to convert the numbers from values less than 1, to values in the 0-100 range (this uses NumPy *broadcasting* to apply the multiplication to each element of the array). This is done to make the numbers easy to look at, as well as demonstrating chaining and broadcasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.1 66.  44.9 12.3]\n",
      " [23.3 68.9 39.7 24.4]]\n"
     ]
    }
   ],
   "source": [
    "a = np.random.rand(2, 4).round(3)*100\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[49.1 20.7 57.2]\n",
      " [85.9  0.3 60.6]]\n"
     ]
    }
   ],
   "source": [
    "b = np.random.rand(2, 3).round(3)*100\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42.7 35.2  6.1 24.8]\n",
      " [69.3 35.6 82.1 17.8]\n",
      " [71.2 76.2 23.  66.6]]\n"
     ]
    }
   ],
   "source": [
    "c = np.random.rand(3, 4).round(3)*100\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that although the above arrays are each different shapes - (2, 4), (2, 3), and (3, 4) - there's always one dimension of each array that has the same size as one dimension of another array. For example, `a` and `b` both have 2 rows, while `b` and `c` each have one dimension of length 3, but `b` has 3 columns while `c` has 3 rows. This allows us to have lots of fun combining these arrays in different ways.\n",
    "\n",
    "NumPy has 'convenience functions' for combining arrays horizontally (adding columns beside columns; `np.hstack()`) and vertically (adding rows below rows; `np.vstack()`). NumPy also has a more generic `np.concatenate()` function that allows either horizontal or vertical concatenation (stacking) using the `axis=` argument. \n",
    "\n",
    "#### Stacking arrays horizontally\n",
    "\n",
    "This will produce an array with `b` and `a` together, 'beside' each other. Note that the inputs have to be inside a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[49.1, 20.7, 57.2,  1.1, 66. , 44.9, 12.3],\n",
       "       [85.9,  0.3, 60.6, 23.3, 68.9, 39.7, 24.4]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.hstack([b, a])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do the same thing with `np.concatenate()`, we include the `axis=1` argument to specify joining on the column axis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[49.1, 20.7, 57.2,  1.1, 66. , 44.9, 12.3],\n",
       "       [85.9,  0.3, 60.6, 23.3, 68.9, 39.7, 24.4]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([b, a], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacking arrays vertically\n",
    "\n",
    "This will produce an array with `c` stacked below `a`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.1, 66. , 44.9, 12.3],\n",
       "       [23.3, 68.9, 39.7, 24.4],\n",
       "       [42.7, 35.2,  6.1, 24.8],\n",
       "       [69.3, 35.6, 82.1, 17.8],\n",
       "       [71.2, 76.2, 23. , 66.6]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack([a, c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we can use `np.concatenate()`, but this time we need to specify `axis=0` to indicate we're stacking on rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.1, 66. , 44.9, 12.3],\n",
       "       [23.3, 68.9, 39.7, 24.4],\n",
       "       [42.7, 35.2,  6.1, 24.8],\n",
       "       [69.3, 35.6, 82.1, 17.8],\n",
       "       [71.2, 76.2, 23. , 66.6]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([a, c], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining pandas arrays\n",
    "\n",
    "NumPy arrays are relatively easy to work with, because they contain only numbers. Real datasets stored in pandas DataFrames present unique challenges, though, because they contain *labelled data*, and often they containg *missing data*. For instance, in a study an individual human participant may provide data on a number of tests, such as a working memory span, reading comprehension, and nonverbal intelligence. Sometimes, for any number of reasons (e.g., time, technical failures, human error), an individual's data on one test may be missing. As another example, in a reaction time (RT) study each participant will complete a large number of trials, resulting in *repeated measures* from the same individual (RT measures on each trial). On some trials, individuals may fail to respond, resulting in missing data for those trials. \n",
    "\n",
    "Missing data creates problems when combining data. Depending on the situation, it may be preferable to replace missing values with null values (which appear in Python as `NaN`, for 'not a number'), or it may be preferable to have complete data and leave out data that we don't have for all of the inputs (e.g., drop the data from one test completely, if we don't have data for every participant).\n",
    "\n",
    "This is where teh terms **inner join** and **outer join** come in. This is a bit of jargon you need to learn, but it's pretty logical. \n",
    "\n",
    "An **outer join** involves filling in missing values with `NaN`. In formal logical terms, this is the *union* of the input data sets. This is the default for `pd.concat()`. You can also think of the names as reflecting the fact that this approach includes all the data within the 'outer' boundaries of the DataFrame, like a box drawn around the entire table.\n",
    "\n",
    "An **inner join** involves keeping only the data that is complete for all inputs. In formal logic, this is the *intersection* of the inputs (i.e., only what they all have in common). You can think of the term 'inner' as referring to the fact that this takes only the data inside that big outer box, that has no missing data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Data\n",
    "\n",
    "Here we have data from two studies of reading and related abilities in children. Each study involved different children. In each study, some of the same measures were collected (such as vocabulary), along with some that were collected in only one study. We'd like to combine the data from the two studies. \n",
    "\n",
    "First, let's load the data from each study and see what we have. Note that I already know that there's a `Participant` column that uniquely identifies each person by an ID code, so we use that as the index for the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 6)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study1 = pd.read_csv('study1.csv', index_col='Participant')\n",
    "study1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So study 1 contains 6 measures from each of 36 participants. Let's look at how the data are structured:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fluency</th>\n",
       "      <th>WordID</th>\n",
       "      <th>Comprehension</th>\n",
       "      <th>Orthoknow</th>\n",
       "      <th>Vocab</th>\n",
       "      <th>PhonAwar</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Participant</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>study1_01</th>\n",
       "      <td>73.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>41</td>\n",
       "      <td>47.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_02</th>\n",
       "      <td>104.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>34</td>\n",
       "      <td>37.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_03</th>\n",
       "      <td>109.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>20</td>\n",
       "      <td>48.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_04</th>\n",
       "      <td>94.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>38</td>\n",
       "      <td>48.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_05</th>\n",
       "      <td>106.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_06</th>\n",
       "      <td>133.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>48</td>\n",
       "      <td>28.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_07</th>\n",
       "      <td>118.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>39</td>\n",
       "      <td>46.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_08</th>\n",
       "      <td>106.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>25</td>\n",
       "      <td>45.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_09</th>\n",
       "      <td>128.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>35</td>\n",
       "      <td>50.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_10</th>\n",
       "      <td>108.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>27</td>\n",
       "      <td>38.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_11</th>\n",
       "      <td>92.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>29</td>\n",
       "      <td>31.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_12</th>\n",
       "      <td>83.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>43</td>\n",
       "      <td>45.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_13</th>\n",
       "      <td>103.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>30</td>\n",
       "      <td>46.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_14</th>\n",
       "      <td>116.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>42</td>\n",
       "      <td>45.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_15</th>\n",
       "      <td>111.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>44</td>\n",
       "      <td>45.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_16</th>\n",
       "      <td>67.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>43</td>\n",
       "      <td>8.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_17</th>\n",
       "      <td>89.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_18</th>\n",
       "      <td>88.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>19</td>\n",
       "      <td>32.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>34</td>\n",
       "      <td>50.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_20</th>\n",
       "      <td>95.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>33</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_21</th>\n",
       "      <td>119.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>25</td>\n",
       "      <td>40.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_22</th>\n",
       "      <td>106.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>48</td>\n",
       "      <td>48.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_23</th>\n",
       "      <td>108.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>34</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_24</th>\n",
       "      <td>64.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>49</td>\n",
       "      <td>49.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_25</th>\n",
       "      <td>94.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33</td>\n",
       "      <td>48.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_26</th>\n",
       "      <td>114.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>42</td>\n",
       "      <td>39.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_27</th>\n",
       "      <td>90.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>25</td>\n",
       "      <td>46.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_28</th>\n",
       "      <td>102.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>39</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_29</th>\n",
       "      <td>99.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>41</td>\n",
       "      <td>33.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_30</th>\n",
       "      <td>96.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>36</td>\n",
       "      <td>46.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_31</th>\n",
       "      <td>69.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>40</td>\n",
       "      <td>46.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_32</th>\n",
       "      <td>79.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>40</td>\n",
       "      <td>43.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_33</th>\n",
       "      <td>91.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>31</td>\n",
       "      <td>49.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_34</th>\n",
       "      <td>64.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>32</td>\n",
       "      <td>46.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_35</th>\n",
       "      <td>125.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>34</td>\n",
       "      <td>33.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_36</th>\n",
       "      <td>114.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>44</td>\n",
       "      <td>37.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Fluency  WordID  Comprehension  Orthoknow  Vocab  PhonAwar\n",
       "Participant                                                            \n",
       "study1_01       73.0    84.0             41       47.0   32.0      31.0\n",
       "study1_02      104.0    45.0             34       37.0   32.0      15.0\n",
       "study1_03      109.0    59.0             20       48.0   31.0      26.0\n",
       "study1_04       94.0    60.0             38       48.0   33.0      29.0\n",
       "study1_05      106.0    66.0             41        NaN   34.0      32.0\n",
       "study1_06      133.0    52.0             48       28.0   41.0      13.0\n",
       "study1_07      118.0    67.0             39       46.0   39.0      28.0\n",
       "study1_08      106.0    71.0             25       45.0   37.0      30.0\n",
       "study1_09      128.0    69.0             35       50.0   29.0      31.0\n",
       "study1_10      108.0    77.0             27       38.0   36.0      32.0\n",
       "study1_11       92.0    54.0             29       31.0   38.0      15.0\n",
       "study1_12       83.0    52.0             43       45.0   34.0      25.0\n",
       "study1_13      103.0    71.0             30       46.0   31.0      30.0\n",
       "study1_14      116.0    51.0             42       45.0   40.0      18.0\n",
       "study1_15      111.0    78.0             44       45.0   40.0      25.0\n",
       "study1_16       67.0    70.0             43        8.0   31.0      19.0\n",
       "study1_17       89.0    52.0             36        NaN   40.0      32.0\n",
       "study1_18       88.0    51.0             19       32.0   33.0      29.0\n",
       "study1_19        NaN    70.0             34       50.0   31.0      24.0\n",
       "study1_20       95.0    84.0             33       38.0   38.0      11.0\n",
       "study1_21      119.0    78.0             25       40.0   34.0      31.0\n",
       "study1_22      106.0    69.0             48       48.0   37.0      15.0\n",
       "study1_23      108.0    63.0             34       45.0    NaN       9.0\n",
       "study1_24       64.0    82.0             49       49.0   34.0      24.0\n",
       "study1_25       94.0     NaN             33       48.0   40.0      21.0\n",
       "study1_26      114.0    65.0             42       39.0   30.0      21.0\n",
       "study1_27       90.0    94.0             25       46.0   42.0      26.0\n",
       "study1_28      102.0    64.0             39       38.0   30.0      32.0\n",
       "study1_29       99.0    73.0             41       33.0   31.0      32.0\n",
       "study1_30       96.0    70.0             36       46.0   32.0      28.0\n",
       "study1_31       69.0    69.0             40       46.0   41.0      32.0\n",
       "study1_32       79.0    65.0             40       43.0   39.0      26.0\n",
       "study1_33       91.0    71.0             31       49.0   34.0      24.0\n",
       "study1_34       64.0    70.0             32       46.0   21.0      14.0\n",
       "study1_35      125.0    78.0             34       33.0   29.0       NaN\n",
       "study1_36      114.0    63.0             44       37.0   33.0      17.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that, since we read in the data without an `index=` argument, the index defaults to numbers. We might want to use the participant ID as the index, but we'll decide on that later. \n",
    "\n",
    "Now let's load the data from the other study and look at it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43, 4)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study2 = pd.read_csv('study2.csv', index_col='Participant')\n",
    "study2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have 4 measures from 43 participants. Again we examine it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comprehension</th>\n",
       "      <th>Vocab</th>\n",
       "      <th>Nonverbal</th>\n",
       "      <th>Fluency</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Participant</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>study2_01</th>\n",
       "      <td>17.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>137.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_02</th>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_05</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_07</th>\n",
       "      <td>34.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_08</th>\n",
       "      <td>28.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_09</th>\n",
       "      <td>21.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_10</th>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_13</th>\n",
       "      <td>39.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>121.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>33.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_17</th>\n",
       "      <td>37.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_18</th>\n",
       "      <td>15.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_20</th>\n",
       "      <td>20.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>108.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_24</th>\n",
       "      <td>29.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_28</th>\n",
       "      <td>28.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_29</th>\n",
       "      <td>34.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_32</th>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_33</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_34</th>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_36</th>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_38</th>\n",
       "      <td>32.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_39</th>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_40</th>\n",
       "      <td>16.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>149.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_41</th>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_42</th>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_43</th>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>113.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_44</th>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_45</th>\n",
       "      <td>34.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_46</th>\n",
       "      <td>34.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>106.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_47</th>\n",
       "      <td>28.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>106.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_48</th>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_49</th>\n",
       "      <td>10.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_50</th>\n",
       "      <td>18.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Comprehension  Vocab  Nonverbal  Fluency\n",
       "Participant                                          \n",
       "study2_01             17.0   15.0       15.0    137.0\n",
       "study2_02              NaN   31.0       21.0    115.0\n",
       "study2_05              NaN    NaN       20.0     95.0\n",
       "study2_07             34.0    7.0       12.0      NaN\n",
       "study2_08             28.0   18.0       10.0     52.0\n",
       "study2_09             21.0   27.0        NaN    130.0\n",
       "study2_10             28.0    NaN        8.0    136.0\n",
       "study2_11              NaN   26.0       17.0     60.0\n",
       "study2_12              NaN   26.0        NaN     97.0\n",
       "study2_13             39.0    NaN        NaN    121.0\n",
       "study2_14              NaN   24.0       22.0     56.0\n",
       "study2_15              NaN   36.0        NaN     24.0\n",
       "study2_16              NaN   33.0        4.0      NaN\n",
       "study2_17             37.0   26.0        NaN     62.0\n",
       "study2_18             15.0   19.0        NaN      NaN\n",
       "study2_19              NaN   18.0       22.0      NaN\n",
       "study2_20             20.0   25.0       22.0     46.0\n",
       "study2_21              NaN   23.0       16.0    108.0\n",
       "study2_23              NaN   31.0       19.0     46.0\n",
       "study2_24             29.0   37.0       18.0    120.0\n",
       "study2_25              NaN   13.0       20.0     35.0\n",
       "study2_26              NaN   28.0       18.0      NaN\n",
       "study2_27              NaN   13.0       23.0     66.0\n",
       "study2_28             28.0   27.0       16.0     55.0\n",
       "study2_29             34.0    9.0       26.0    120.0\n",
       "study2_30              NaN   20.0       17.0    127.0\n",
       "study2_32             18.0    NaN       20.0     88.0\n",
       "study2_33              NaN    NaN       18.0     80.0\n",
       "study2_34              NaN   28.0       18.0      NaN\n",
       "study2_36             19.0    NaN       22.0    107.0\n",
       "study2_38             32.0   14.0       18.0     42.0\n",
       "study2_39              NaN   32.0       21.0     89.0\n",
       "study2_40             16.0   31.0       20.0    149.0\n",
       "study2_41              NaN   26.0       20.0     63.0\n",
       "study2_42              NaN   30.0       20.0     76.0\n",
       "study2_43              NaN   27.0       17.0    113.0\n",
       "study2_44              NaN   23.0       14.0     97.0\n",
       "study2_45             34.0   25.0       20.0     53.0\n",
       "study2_46             34.0   22.0        8.0    106.0\n",
       "study2_47             28.0   33.0       14.0    106.0\n",
       "study2_48              NaN   18.0       17.0      NaN\n",
       "study2_49             10.0   32.0       22.0     77.0\n",
       "study2_50             18.0   23.0       15.0    101.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the two datasets, we can see that there are three measures in common across the two studies: `Fluency`, `Comprehension`, and `Vocab`. Each study also has unique measures, for which we don't have data in the other study: study 1 has `WordID`, `Orthoknow`, and `PhonAwar`, while study 2 has `Nonverbal`. \n",
    "\n",
    "The other thing to note is that in both datasets, there are missing data (`NaN`); for some participants we are missing data on some tests. \n",
    "\n",
    "#### Combining the data sets\n",
    "\n",
    "Now that we have an idea of what we're working with, we can think about how to combine these two datasets using `pd.concat()`. The first question is whether horizontal or vertical concatenation makes more sense. Since each row of data in each data set corresponds to one individual, it really doesn't make sense to combine these horizontally. So we want to concatenate vertically, stacking the rows. For this we use the `axis=0` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fluency</th>\n",
       "      <th>WordID</th>\n",
       "      <th>Comprehension</th>\n",
       "      <th>Orthoknow</th>\n",
       "      <th>Vocab</th>\n",
       "      <th>PhonAwar</th>\n",
       "      <th>Nonverbal</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Participant</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>study1_01</th>\n",
       "      <td>73.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_02</th>\n",
       "      <td>104.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_03</th>\n",
       "      <td>109.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_04</th>\n",
       "      <td>94.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_05</th>\n",
       "      <td>106.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_06</th>\n",
       "      <td>133.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_07</th>\n",
       "      <td>118.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_08</th>\n",
       "      <td>106.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_09</th>\n",
       "      <td>128.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_10</th>\n",
       "      <td>108.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_11</th>\n",
       "      <td>92.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_12</th>\n",
       "      <td>83.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_13</th>\n",
       "      <td>103.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_14</th>\n",
       "      <td>116.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_15</th>\n",
       "      <td>111.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_16</th>\n",
       "      <td>67.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_17</th>\n",
       "      <td>89.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_18</th>\n",
       "      <td>88.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_20</th>\n",
       "      <td>95.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_21</th>\n",
       "      <td>119.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_22</th>\n",
       "      <td>106.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_23</th>\n",
       "      <td>108.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_24</th>\n",
       "      <td>64.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_25</th>\n",
       "      <td>94.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_26</th>\n",
       "      <td>114.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_27</th>\n",
       "      <td>90.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_28</th>\n",
       "      <td>102.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_29</th>\n",
       "      <td>99.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_30</th>\n",
       "      <td>96.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_31</th>\n",
       "      <td>69.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_32</th>\n",
       "      <td>79.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_33</th>\n",
       "      <td>91.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_34</th>\n",
       "      <td>64.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_35</th>\n",
       "      <td>125.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_36</th>\n",
       "      <td>114.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_01</th>\n",
       "      <td>137.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_02</th>\n",
       "      <td>115.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_05</th>\n",
       "      <td>95.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_07</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_08</th>\n",
       "      <td>52.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_09</th>\n",
       "      <td>130.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_10</th>\n",
       "      <td>136.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_11</th>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_12</th>\n",
       "      <td>97.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_13</th>\n",
       "      <td>121.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_14</th>\n",
       "      <td>56.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_15</th>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_17</th>\n",
       "      <td>62.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_20</th>\n",
       "      <td>46.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_21</th>\n",
       "      <td>108.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_23</th>\n",
       "      <td>46.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_24</th>\n",
       "      <td>120.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_25</th>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_27</th>\n",
       "      <td>66.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_28</th>\n",
       "      <td>55.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_29</th>\n",
       "      <td>120.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_30</th>\n",
       "      <td>127.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_32</th>\n",
       "      <td>88.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_33</th>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_34</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_36</th>\n",
       "      <td>107.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_38</th>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_39</th>\n",
       "      <td>89.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_40</th>\n",
       "      <td>149.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_41</th>\n",
       "      <td>63.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_42</th>\n",
       "      <td>76.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_43</th>\n",
       "      <td>113.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_44</th>\n",
       "      <td>97.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_45</th>\n",
       "      <td>53.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_46</th>\n",
       "      <td>106.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_47</th>\n",
       "      <td>106.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_48</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_49</th>\n",
       "      <td>77.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_50</th>\n",
       "      <td>101.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Fluency  WordID  Comprehension  Orthoknow  Vocab  PhonAwar  \\\n",
       "Participant                                                               \n",
       "study1_01       73.0    84.0           41.0       47.0   32.0      31.0   \n",
       "study1_02      104.0    45.0           34.0       37.0   32.0      15.0   \n",
       "study1_03      109.0    59.0           20.0       48.0   31.0      26.0   \n",
       "study1_04       94.0    60.0           38.0       48.0   33.0      29.0   \n",
       "study1_05      106.0    66.0           41.0        NaN   34.0      32.0   \n",
       "study1_06      133.0    52.0           48.0       28.0   41.0      13.0   \n",
       "study1_07      118.0    67.0           39.0       46.0   39.0      28.0   \n",
       "study1_08      106.0    71.0           25.0       45.0   37.0      30.0   \n",
       "study1_09      128.0    69.0           35.0       50.0   29.0      31.0   \n",
       "study1_10      108.0    77.0           27.0       38.0   36.0      32.0   \n",
       "study1_11       92.0    54.0           29.0       31.0   38.0      15.0   \n",
       "study1_12       83.0    52.0           43.0       45.0   34.0      25.0   \n",
       "study1_13      103.0    71.0           30.0       46.0   31.0      30.0   \n",
       "study1_14      116.0    51.0           42.0       45.0   40.0      18.0   \n",
       "study1_15      111.0    78.0           44.0       45.0   40.0      25.0   \n",
       "study1_16       67.0    70.0           43.0        8.0   31.0      19.0   \n",
       "study1_17       89.0    52.0           36.0        NaN   40.0      32.0   \n",
       "study1_18       88.0    51.0           19.0       32.0   33.0      29.0   \n",
       "study1_19        NaN    70.0           34.0       50.0   31.0      24.0   \n",
       "study1_20       95.0    84.0           33.0       38.0   38.0      11.0   \n",
       "study1_21      119.0    78.0           25.0       40.0   34.0      31.0   \n",
       "study1_22      106.0    69.0           48.0       48.0   37.0      15.0   \n",
       "study1_23      108.0    63.0           34.0       45.0    NaN       9.0   \n",
       "study1_24       64.0    82.0           49.0       49.0   34.0      24.0   \n",
       "study1_25       94.0     NaN           33.0       48.0   40.0      21.0   \n",
       "study1_26      114.0    65.0           42.0       39.0   30.0      21.0   \n",
       "study1_27       90.0    94.0           25.0       46.0   42.0      26.0   \n",
       "study1_28      102.0    64.0           39.0       38.0   30.0      32.0   \n",
       "study1_29       99.0    73.0           41.0       33.0   31.0      32.0   \n",
       "study1_30       96.0    70.0           36.0       46.0   32.0      28.0   \n",
       "study1_31       69.0    69.0           40.0       46.0   41.0      32.0   \n",
       "study1_32       79.0    65.0           40.0       43.0   39.0      26.0   \n",
       "study1_33       91.0    71.0           31.0       49.0   34.0      24.0   \n",
       "study1_34       64.0    70.0           32.0       46.0   21.0      14.0   \n",
       "study1_35      125.0    78.0           34.0       33.0   29.0       NaN   \n",
       "study1_36      114.0    63.0           44.0       37.0   33.0      17.0   \n",
       "study2_01      137.0     NaN           17.0        NaN   15.0       NaN   \n",
       "study2_02      115.0     NaN            NaN        NaN   31.0       NaN   \n",
       "study2_05       95.0     NaN            NaN        NaN    NaN       NaN   \n",
       "study2_07        NaN     NaN           34.0        NaN    7.0       NaN   \n",
       "study2_08       52.0     NaN           28.0        NaN   18.0       NaN   \n",
       "study2_09      130.0     NaN           21.0        NaN   27.0       NaN   \n",
       "study2_10      136.0     NaN           28.0        NaN    NaN       NaN   \n",
       "study2_11       60.0     NaN            NaN        NaN   26.0       NaN   \n",
       "study2_12       97.0     NaN            NaN        NaN   26.0       NaN   \n",
       "study2_13      121.0     NaN           39.0        NaN    NaN       NaN   \n",
       "study2_14       56.0     NaN            NaN        NaN   24.0       NaN   \n",
       "study2_15       24.0     NaN            NaN        NaN   36.0       NaN   \n",
       "study2_16        NaN     NaN            NaN        NaN   33.0       NaN   \n",
       "study2_17       62.0     NaN           37.0        NaN   26.0       NaN   \n",
       "study2_18        NaN     NaN           15.0        NaN   19.0       NaN   \n",
       "study2_19        NaN     NaN            NaN        NaN   18.0       NaN   \n",
       "study2_20       46.0     NaN           20.0        NaN   25.0       NaN   \n",
       "study2_21      108.0     NaN            NaN        NaN   23.0       NaN   \n",
       "study2_23       46.0     NaN            NaN        NaN   31.0       NaN   \n",
       "study2_24      120.0     NaN           29.0        NaN   37.0       NaN   \n",
       "study2_25       35.0     NaN            NaN        NaN   13.0       NaN   \n",
       "study2_26        NaN     NaN            NaN        NaN   28.0       NaN   \n",
       "study2_27       66.0     NaN            NaN        NaN   13.0       NaN   \n",
       "study2_28       55.0     NaN           28.0        NaN   27.0       NaN   \n",
       "study2_29      120.0     NaN           34.0        NaN    9.0       NaN   \n",
       "study2_30      127.0     NaN            NaN        NaN   20.0       NaN   \n",
       "study2_32       88.0     NaN           18.0        NaN    NaN       NaN   \n",
       "study2_33       80.0     NaN            NaN        NaN    NaN       NaN   \n",
       "study2_34        NaN     NaN            NaN        NaN   28.0       NaN   \n",
       "study2_36      107.0     NaN           19.0        NaN    NaN       NaN   \n",
       "study2_38       42.0     NaN           32.0        NaN   14.0       NaN   \n",
       "study2_39       89.0     NaN            NaN        NaN   32.0       NaN   \n",
       "study2_40      149.0     NaN           16.0        NaN   31.0       NaN   \n",
       "study2_41       63.0     NaN            NaN        NaN   26.0       NaN   \n",
       "study2_42       76.0     NaN            NaN        NaN   30.0       NaN   \n",
       "study2_43      113.0     NaN            NaN        NaN   27.0       NaN   \n",
       "study2_44       97.0     NaN            NaN        NaN   23.0       NaN   \n",
       "study2_45       53.0     NaN           34.0        NaN   25.0       NaN   \n",
       "study2_46      106.0     NaN           34.0        NaN   22.0       NaN   \n",
       "study2_47      106.0     NaN           28.0        NaN   33.0       NaN   \n",
       "study2_48        NaN     NaN            NaN        NaN   18.0       NaN   \n",
       "study2_49       77.0     NaN           10.0        NaN   32.0       NaN   \n",
       "study2_50      101.0     NaN           18.0        NaN   23.0       NaN   \n",
       "\n",
       "             Nonverbal  \n",
       "Participant             \n",
       "study1_01          NaN  \n",
       "study1_02          NaN  \n",
       "study1_03          NaN  \n",
       "study1_04          NaN  \n",
       "study1_05          NaN  \n",
       "study1_06          NaN  \n",
       "study1_07          NaN  \n",
       "study1_08          NaN  \n",
       "study1_09          NaN  \n",
       "study1_10          NaN  \n",
       "study1_11          NaN  \n",
       "study1_12          NaN  \n",
       "study1_13          NaN  \n",
       "study1_14          NaN  \n",
       "study1_15          NaN  \n",
       "study1_16          NaN  \n",
       "study1_17          NaN  \n",
       "study1_18          NaN  \n",
       "study1_19          NaN  \n",
       "study1_20          NaN  \n",
       "study1_21          NaN  \n",
       "study1_22          NaN  \n",
       "study1_23          NaN  \n",
       "study1_24          NaN  \n",
       "study1_25          NaN  \n",
       "study1_26          NaN  \n",
       "study1_27          NaN  \n",
       "study1_28          NaN  \n",
       "study1_29          NaN  \n",
       "study1_30          NaN  \n",
       "study1_31          NaN  \n",
       "study1_32          NaN  \n",
       "study1_33          NaN  \n",
       "study1_34          NaN  \n",
       "study1_35          NaN  \n",
       "study1_36          NaN  \n",
       "study2_01         15.0  \n",
       "study2_02         21.0  \n",
       "study2_05         20.0  \n",
       "study2_07         12.0  \n",
       "study2_08         10.0  \n",
       "study2_09          NaN  \n",
       "study2_10          8.0  \n",
       "study2_11         17.0  \n",
       "study2_12          NaN  \n",
       "study2_13          NaN  \n",
       "study2_14         22.0  \n",
       "study2_15          NaN  \n",
       "study2_16          4.0  \n",
       "study2_17          NaN  \n",
       "study2_18          NaN  \n",
       "study2_19         22.0  \n",
       "study2_20         22.0  \n",
       "study2_21         16.0  \n",
       "study2_23         19.0  \n",
       "study2_24         18.0  \n",
       "study2_25         20.0  \n",
       "study2_26         18.0  \n",
       "study2_27         23.0  \n",
       "study2_28         16.0  \n",
       "study2_29         26.0  \n",
       "study2_30         17.0  \n",
       "study2_32         20.0  \n",
       "study2_33         18.0  \n",
       "study2_34         18.0  \n",
       "study2_36         22.0  \n",
       "study2_38         18.0  \n",
       "study2_39         21.0  \n",
       "study2_40         20.0  \n",
       "study2_41         20.0  \n",
       "study2_42         20.0  \n",
       "study2_43         17.0  \n",
       "study2_44         14.0  \n",
       "study2_45         20.0  \n",
       "study2_46          8.0  \n",
       "study2_47         14.0  \n",
       "study2_48         17.0  \n",
       "study2_49         22.0  \n",
       "study2_50         15.0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "studies_1_2 = pd.concat([study1, study2], axis=0)\n",
    "studies_1_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see above that pandas preserved all of the columns from both inputs, combining the data for column labels that existed in both data sets, and inserting `NaN` in any column that was only present in one of the data sets, for the participants who did not provide data on that measure.\n",
    "\n",
    "Again, this is called an **outer join**, and is the default for `pd.concat()`. In some data analysis situations, we might only want to analyze data from *complete cases* — measures for which there is no missing data. To do this, we would perform an **inner join**, which includes only the data from complete cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fluency</th>\n",
       "      <th>Comprehension</th>\n",
       "      <th>Vocab</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Participant</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>study1_01</th>\n",
       "      <td>73.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_02</th>\n",
       "      <td>104.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_03</th>\n",
       "      <td>109.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_04</th>\n",
       "      <td>94.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_05</th>\n",
       "      <td>106.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_06</th>\n",
       "      <td>133.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_07</th>\n",
       "      <td>118.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_08</th>\n",
       "      <td>106.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_09</th>\n",
       "      <td>128.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_10</th>\n",
       "      <td>108.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_11</th>\n",
       "      <td>92.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_12</th>\n",
       "      <td>83.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_13</th>\n",
       "      <td>103.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_14</th>\n",
       "      <td>116.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_15</th>\n",
       "      <td>111.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_16</th>\n",
       "      <td>67.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_17</th>\n",
       "      <td>89.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_18</th>\n",
       "      <td>88.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_20</th>\n",
       "      <td>95.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_21</th>\n",
       "      <td>119.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_22</th>\n",
       "      <td>106.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_23</th>\n",
       "      <td>108.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_24</th>\n",
       "      <td>64.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_25</th>\n",
       "      <td>94.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_26</th>\n",
       "      <td>114.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_27</th>\n",
       "      <td>90.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_28</th>\n",
       "      <td>102.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_29</th>\n",
       "      <td>99.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_30</th>\n",
       "      <td>96.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_31</th>\n",
       "      <td>69.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_32</th>\n",
       "      <td>79.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_33</th>\n",
       "      <td>91.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_34</th>\n",
       "      <td>64.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_35</th>\n",
       "      <td>125.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_36</th>\n",
       "      <td>114.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_01</th>\n",
       "      <td>137.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_02</th>\n",
       "      <td>115.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_05</th>\n",
       "      <td>95.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_07</th>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_08</th>\n",
       "      <td>52.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_09</th>\n",
       "      <td>130.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_10</th>\n",
       "      <td>136.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_11</th>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_12</th>\n",
       "      <td>97.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_13</th>\n",
       "      <td>121.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_14</th>\n",
       "      <td>56.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_15</th>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_17</th>\n",
       "      <td>62.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_20</th>\n",
       "      <td>46.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_21</th>\n",
       "      <td>108.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_23</th>\n",
       "      <td>46.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_24</th>\n",
       "      <td>120.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_25</th>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_27</th>\n",
       "      <td>66.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_28</th>\n",
       "      <td>55.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_29</th>\n",
       "      <td>120.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_30</th>\n",
       "      <td>127.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_32</th>\n",
       "      <td>88.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_33</th>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_34</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_36</th>\n",
       "      <td>107.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_38</th>\n",
       "      <td>42.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_39</th>\n",
       "      <td>89.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_40</th>\n",
       "      <td>149.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_41</th>\n",
       "      <td>63.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_42</th>\n",
       "      <td>76.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_43</th>\n",
       "      <td>113.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_44</th>\n",
       "      <td>97.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_45</th>\n",
       "      <td>53.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_46</th>\n",
       "      <td>106.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_47</th>\n",
       "      <td>106.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_48</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_49</th>\n",
       "      <td>77.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_50</th>\n",
       "      <td>101.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Fluency  Comprehension  Vocab\n",
       "Participant                               \n",
       "study1_01       73.0           41.0   32.0\n",
       "study1_02      104.0           34.0   32.0\n",
       "study1_03      109.0           20.0   31.0\n",
       "study1_04       94.0           38.0   33.0\n",
       "study1_05      106.0           41.0   34.0\n",
       "study1_06      133.0           48.0   41.0\n",
       "study1_07      118.0           39.0   39.0\n",
       "study1_08      106.0           25.0   37.0\n",
       "study1_09      128.0           35.0   29.0\n",
       "study1_10      108.0           27.0   36.0\n",
       "study1_11       92.0           29.0   38.0\n",
       "study1_12       83.0           43.0   34.0\n",
       "study1_13      103.0           30.0   31.0\n",
       "study1_14      116.0           42.0   40.0\n",
       "study1_15      111.0           44.0   40.0\n",
       "study1_16       67.0           43.0   31.0\n",
       "study1_17       89.0           36.0   40.0\n",
       "study1_18       88.0           19.0   33.0\n",
       "study1_19        NaN           34.0   31.0\n",
       "study1_20       95.0           33.0   38.0\n",
       "study1_21      119.0           25.0   34.0\n",
       "study1_22      106.0           48.0   37.0\n",
       "study1_23      108.0           34.0    NaN\n",
       "study1_24       64.0           49.0   34.0\n",
       "study1_25       94.0           33.0   40.0\n",
       "study1_26      114.0           42.0   30.0\n",
       "study1_27       90.0           25.0   42.0\n",
       "study1_28      102.0           39.0   30.0\n",
       "study1_29       99.0           41.0   31.0\n",
       "study1_30       96.0           36.0   32.0\n",
       "study1_31       69.0           40.0   41.0\n",
       "study1_32       79.0           40.0   39.0\n",
       "study1_33       91.0           31.0   34.0\n",
       "study1_34       64.0           32.0   21.0\n",
       "study1_35      125.0           34.0   29.0\n",
       "study1_36      114.0           44.0   33.0\n",
       "study2_01      137.0           17.0   15.0\n",
       "study2_02      115.0            NaN   31.0\n",
       "study2_05       95.0            NaN    NaN\n",
       "study2_07        NaN           34.0    7.0\n",
       "study2_08       52.0           28.0   18.0\n",
       "study2_09      130.0           21.0   27.0\n",
       "study2_10      136.0           28.0    NaN\n",
       "study2_11       60.0            NaN   26.0\n",
       "study2_12       97.0            NaN   26.0\n",
       "study2_13      121.0           39.0    NaN\n",
       "study2_14       56.0            NaN   24.0\n",
       "study2_15       24.0            NaN   36.0\n",
       "study2_16        NaN            NaN   33.0\n",
       "study2_17       62.0           37.0   26.0\n",
       "study2_18        NaN           15.0   19.0\n",
       "study2_19        NaN            NaN   18.0\n",
       "study2_20       46.0           20.0   25.0\n",
       "study2_21      108.0            NaN   23.0\n",
       "study2_23       46.0            NaN   31.0\n",
       "study2_24      120.0           29.0   37.0\n",
       "study2_25       35.0            NaN   13.0\n",
       "study2_26        NaN            NaN   28.0\n",
       "study2_27       66.0            NaN   13.0\n",
       "study2_28       55.0           28.0   27.0\n",
       "study2_29      120.0           34.0    9.0\n",
       "study2_30      127.0            NaN   20.0\n",
       "study2_32       88.0           18.0    NaN\n",
       "study2_33       80.0            NaN    NaN\n",
       "study2_34        NaN            NaN   28.0\n",
       "study2_36      107.0           19.0    NaN\n",
       "study2_38       42.0           32.0   14.0\n",
       "study2_39       89.0            NaN   32.0\n",
       "study2_40      149.0           16.0   31.0\n",
       "study2_41       63.0            NaN   26.0\n",
       "study2_42       76.0            NaN   30.0\n",
       "study2_43      113.0            NaN   27.0\n",
       "study2_44       97.0            NaN   23.0\n",
       "study2_45       53.0           34.0   25.0\n",
       "study2_46      106.0           34.0   22.0\n",
       "study2_47      106.0           28.0   33.0\n",
       "study2_48        NaN            NaN   18.0\n",
       "study2_49       77.0           10.0   32.0\n",
       "study2_50      101.0           18.0   23.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "studies_1_2 = pd.concat([study1, study2], axis=0, join='inner')\n",
    "studies_1_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above you can see that only the `Participant`, `Fluency`, `Comprehension`, and `Vocab` columns were kept; the others were discarded. \n",
    "\n",
    "Note however that there are still `NaN` values for some participants, for some measures. In other words, our inner join only applied to the columns and not to the rows. If we truly want complete cases, and therefor wish to drop any participant with missing data, we can use the `.dropna()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fluency</th>\n",
       "      <th>Comprehension</th>\n",
       "      <th>Vocab</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Participant</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>study1_01</th>\n",
       "      <td>73.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_02</th>\n",
       "      <td>104.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_03</th>\n",
       "      <td>109.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_04</th>\n",
       "      <td>94.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_05</th>\n",
       "      <td>106.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_06</th>\n",
       "      <td>133.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_07</th>\n",
       "      <td>118.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_08</th>\n",
       "      <td>106.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_09</th>\n",
       "      <td>128.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_10</th>\n",
       "      <td>108.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_11</th>\n",
       "      <td>92.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_12</th>\n",
       "      <td>83.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_13</th>\n",
       "      <td>103.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_14</th>\n",
       "      <td>116.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_15</th>\n",
       "      <td>111.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_16</th>\n",
       "      <td>67.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_17</th>\n",
       "      <td>89.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_18</th>\n",
       "      <td>88.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_20</th>\n",
       "      <td>95.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_21</th>\n",
       "      <td>119.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_22</th>\n",
       "      <td>106.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_24</th>\n",
       "      <td>64.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_25</th>\n",
       "      <td>94.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_26</th>\n",
       "      <td>114.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_27</th>\n",
       "      <td>90.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_28</th>\n",
       "      <td>102.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_29</th>\n",
       "      <td>99.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_30</th>\n",
       "      <td>96.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_31</th>\n",
       "      <td>69.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_32</th>\n",
       "      <td>79.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_33</th>\n",
       "      <td>91.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_34</th>\n",
       "      <td>64.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_35</th>\n",
       "      <td>125.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_36</th>\n",
       "      <td>114.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_01</th>\n",
       "      <td>137.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_08</th>\n",
       "      <td>52.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_09</th>\n",
       "      <td>130.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_17</th>\n",
       "      <td>62.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_20</th>\n",
       "      <td>46.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_24</th>\n",
       "      <td>120.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_28</th>\n",
       "      <td>55.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_29</th>\n",
       "      <td>120.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_38</th>\n",
       "      <td>42.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_40</th>\n",
       "      <td>149.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_45</th>\n",
       "      <td>53.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_46</th>\n",
       "      <td>106.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_47</th>\n",
       "      <td>106.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_49</th>\n",
       "      <td>77.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_50</th>\n",
       "      <td>101.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Fluency  Comprehension  Vocab\n",
       "Participant                               \n",
       "study1_01       73.0           41.0   32.0\n",
       "study1_02      104.0           34.0   32.0\n",
       "study1_03      109.0           20.0   31.0\n",
       "study1_04       94.0           38.0   33.0\n",
       "study1_05      106.0           41.0   34.0\n",
       "study1_06      133.0           48.0   41.0\n",
       "study1_07      118.0           39.0   39.0\n",
       "study1_08      106.0           25.0   37.0\n",
       "study1_09      128.0           35.0   29.0\n",
       "study1_10      108.0           27.0   36.0\n",
       "study1_11       92.0           29.0   38.0\n",
       "study1_12       83.0           43.0   34.0\n",
       "study1_13      103.0           30.0   31.0\n",
       "study1_14      116.0           42.0   40.0\n",
       "study1_15      111.0           44.0   40.0\n",
       "study1_16       67.0           43.0   31.0\n",
       "study1_17       89.0           36.0   40.0\n",
       "study1_18       88.0           19.0   33.0\n",
       "study1_20       95.0           33.0   38.0\n",
       "study1_21      119.0           25.0   34.0\n",
       "study1_22      106.0           48.0   37.0\n",
       "study1_24       64.0           49.0   34.0\n",
       "study1_25       94.0           33.0   40.0\n",
       "study1_26      114.0           42.0   30.0\n",
       "study1_27       90.0           25.0   42.0\n",
       "study1_28      102.0           39.0   30.0\n",
       "study1_29       99.0           41.0   31.0\n",
       "study1_30       96.0           36.0   32.0\n",
       "study1_31       69.0           40.0   41.0\n",
       "study1_32       79.0           40.0   39.0\n",
       "study1_33       91.0           31.0   34.0\n",
       "study1_34       64.0           32.0   21.0\n",
       "study1_35      125.0           34.0   29.0\n",
       "study1_36      114.0           44.0   33.0\n",
       "study2_01      137.0           17.0   15.0\n",
       "study2_08       52.0           28.0   18.0\n",
       "study2_09      130.0           21.0   27.0\n",
       "study2_17       62.0           37.0   26.0\n",
       "study2_20       46.0           20.0   25.0\n",
       "study2_24      120.0           29.0   37.0\n",
       "study2_28       55.0           28.0   27.0\n",
       "study2_29      120.0           34.0    9.0\n",
       "study2_38       42.0           32.0   14.0\n",
       "study2_40      149.0           16.0   31.0\n",
       "study2_45       53.0           34.0   25.0\n",
       "study2_46      106.0           34.0   22.0\n",
       "study2_47      106.0           28.0   33.0\n",
       "study2_49       77.0           10.0   32.0\n",
       "study2_50      101.0           18.0   23.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "studies_1_2.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can combine this with `pd.concat()` through chaining, to achieve the full result in one line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fluency</th>\n",
       "      <th>Comprehension</th>\n",
       "      <th>Vocab</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Participant</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>study1_01</th>\n",
       "      <td>73.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_02</th>\n",
       "      <td>104.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_03</th>\n",
       "      <td>109.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_04</th>\n",
       "      <td>94.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_05</th>\n",
       "      <td>106.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_06</th>\n",
       "      <td>133.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_07</th>\n",
       "      <td>118.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_08</th>\n",
       "      <td>106.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_09</th>\n",
       "      <td>128.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_10</th>\n",
       "      <td>108.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_11</th>\n",
       "      <td>92.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_12</th>\n",
       "      <td>83.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_13</th>\n",
       "      <td>103.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_14</th>\n",
       "      <td>116.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_15</th>\n",
       "      <td>111.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_16</th>\n",
       "      <td>67.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_17</th>\n",
       "      <td>89.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_18</th>\n",
       "      <td>88.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_20</th>\n",
       "      <td>95.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_21</th>\n",
       "      <td>119.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_22</th>\n",
       "      <td>106.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_24</th>\n",
       "      <td>64.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_25</th>\n",
       "      <td>94.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_26</th>\n",
       "      <td>114.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_27</th>\n",
       "      <td>90.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_28</th>\n",
       "      <td>102.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_29</th>\n",
       "      <td>99.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_30</th>\n",
       "      <td>96.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_31</th>\n",
       "      <td>69.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_32</th>\n",
       "      <td>79.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_33</th>\n",
       "      <td>91.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_34</th>\n",
       "      <td>64.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_35</th>\n",
       "      <td>125.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study1_36</th>\n",
       "      <td>114.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_01</th>\n",
       "      <td>137.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_08</th>\n",
       "      <td>52.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_09</th>\n",
       "      <td>130.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_17</th>\n",
       "      <td>62.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_20</th>\n",
       "      <td>46.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_24</th>\n",
       "      <td>120.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_28</th>\n",
       "      <td>55.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_29</th>\n",
       "      <td>120.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_38</th>\n",
       "      <td>42.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_40</th>\n",
       "      <td>149.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_45</th>\n",
       "      <td>53.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_46</th>\n",
       "      <td>106.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_47</th>\n",
       "      <td>106.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_49</th>\n",
       "      <td>77.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study2_50</th>\n",
       "      <td>101.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Fluency  Comprehension  Vocab\n",
       "Participant                               \n",
       "study1_01       73.0           41.0   32.0\n",
       "study1_02      104.0           34.0   32.0\n",
       "study1_03      109.0           20.0   31.0\n",
       "study1_04       94.0           38.0   33.0\n",
       "study1_05      106.0           41.0   34.0\n",
       "study1_06      133.0           48.0   41.0\n",
       "study1_07      118.0           39.0   39.0\n",
       "study1_08      106.0           25.0   37.0\n",
       "study1_09      128.0           35.0   29.0\n",
       "study1_10      108.0           27.0   36.0\n",
       "study1_11       92.0           29.0   38.0\n",
       "study1_12       83.0           43.0   34.0\n",
       "study1_13      103.0           30.0   31.0\n",
       "study1_14      116.0           42.0   40.0\n",
       "study1_15      111.0           44.0   40.0\n",
       "study1_16       67.0           43.0   31.0\n",
       "study1_17       89.0           36.0   40.0\n",
       "study1_18       88.0           19.0   33.0\n",
       "study1_20       95.0           33.0   38.0\n",
       "study1_21      119.0           25.0   34.0\n",
       "study1_22      106.0           48.0   37.0\n",
       "study1_24       64.0           49.0   34.0\n",
       "study1_25       94.0           33.0   40.0\n",
       "study1_26      114.0           42.0   30.0\n",
       "study1_27       90.0           25.0   42.0\n",
       "study1_28      102.0           39.0   30.0\n",
       "study1_29       99.0           41.0   31.0\n",
       "study1_30       96.0           36.0   32.0\n",
       "study1_31       69.0           40.0   41.0\n",
       "study1_32       79.0           40.0   39.0\n",
       "study1_33       91.0           31.0   34.0\n",
       "study1_34       64.0           32.0   21.0\n",
       "study1_35      125.0           34.0   29.0\n",
       "study1_36      114.0           44.0   33.0\n",
       "study2_01      137.0           17.0   15.0\n",
       "study2_08       52.0           28.0   18.0\n",
       "study2_09      130.0           21.0   27.0\n",
       "study2_17       62.0           37.0   26.0\n",
       "study2_20       46.0           20.0   25.0\n",
       "study2_24      120.0           29.0   37.0\n",
       "study2_28       55.0           28.0   27.0\n",
       "study2_29      120.0           34.0    9.0\n",
       "study2_38       42.0           32.0   14.0\n",
       "study2_40      149.0           16.0   31.0\n",
       "study2_45       53.0           34.0   25.0\n",
       "study2_46      106.0           34.0   22.0\n",
       "study2_47      106.0           28.0   33.0\n",
       "study2_49       77.0           10.0   32.0\n",
       "study2_50      101.0           18.0   23.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "studies_1_2 = pd.concat([study1, study2], axis=0, join='inner').dropna(axis=0)\n",
    "studies_1_2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
