{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-53b06d85acb414e6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Exercises – Reaction Time Data\n",
    "\n",
    "- [Download all the Jupyter notebooks and other files you need to complete the lessons in this chapter (Chapter 3b)](https://github.com/neural-data-science/AI-Assisted-Coding)\n",
    "\n",
    "---\n",
    "\n",
    "This section is based on a former assignment for this course. With GitHub Copilot, the assignment has become too easy to be used as an assignment. Instead, we will use it as an exercise to practice using GitHub Copilot. At the same time, we're introducing some data that you might encounter in neuroscience research: behavioral reaction times (RTs), and errors. While these are not direct measurements of neural activity, they reflect neural processes, and are often important to analyze in order to properly interpret the results of a neuroscience experiment – one often cannot understand what the brain is doing, if one does not understand what the associated behavior is.\n",
    "\n",
    "In the online textbook, this lesson is populated with code generated by Copilot, based on prompts that more or less match the assignment instructions. This is because in the textbook, we want to show you how Copilot works, and how it can be used to generate code. However, in the exercises you can download, you will get a notebook without code or prompts. This is because we want you to write the code yourself, ideally without peeking at the solutions in the textbook (so don't read below this cell if you want to do the exercise!).\n",
    "\n",
    "It is **highly recommended** that if you are working through the lesson yourself, you deactivate Copilot. If you really get stuck, you can always reactivate Copilot to get a hint, but then deactivate it again to write the next bit of code yourself. But you will learn a lot more about code by trying to write it yourself. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "783ace",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Reaction Time Data\n",
    "\n",
    "The cell below contains reaction times (RT; in seconds) from some trials in a behavioral experiment. The RTs reflect the amount of time between when a stimulus was presented, and when a human participant responded by making a button press. Execute the cell (shift-enter) and move on to the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "5e78be",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "rt = [0.394252808, 0.442094359, 0.534764366, 0.565906723, 0.570404592, \n",
    "      0.486154719, 0.518792127, 0.844916827, 0.495622859, 0.476159436, \n",
    "      0.612854746, 0.529661203, 0.389157455, 1.517088266, 0.573962432, \n",
    "      0.714152493, 0.409225638, 0.435308188, 0.509801957, 0.544626271, \n",
    "      0.437877745, 0.333356848, 0.401773569, 0.479840688\n",
    "      ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "e1a008",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 1\n",
    "What *type* of data is `rt` (in terms of Python data types)? Use a Python command to generate the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "q1",
     "locked": false,
     "points": 1,
     "remove": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what type of data is rt\n",
    "type(rt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "54b0df",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 2\n",
    "\n",
    "What *type* of data is the first value in `rt` (in terms of Python data types)? Use a Python command to generate the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "q2",
     "locked": false,
     "points": 1,
     "remove": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what type of data is the first element of rt\n",
    "type(rt[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d63971c00d3fc361",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 3\n",
    "\n",
    "How many trials were in this experiment? (Hint: how many entries are there in `rt`?). Use Python code to generate the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-b80a9b67f0dd05a8",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many trials were in this experiment\n",
    "# how many entries are in rt\n",
    "len(rt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "gggdsgf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 4\n",
    "\n",
    "Print the first 9 values in `rt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "q3",
     "locked": false,
     "points": 1,
     "remove": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.394252808,\n",
       " 0.442094359,\n",
       " 0.534764366,\n",
       " 0.565906723,\n",
       " 0.570404592,\n",
       " 0.486154719,\n",
       " 0.518792127,\n",
       " 0.844916827,\n",
       " 0.495622859]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the fist 9 elements of rt\n",
    "rt[0:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "fa27a5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 5\n",
    "\n",
    "Print the last 6 values in `rt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "q4",
     "locked": false,
     "points": 1,
     "remove": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.509801957, 0.544626271, 0.437877745, 0.333356848, 0.401773569, 0.479840688]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the last 6 elements of rt\n",
    "rt[-6:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "ae48ef",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 6\n",
    "\n",
    "Print the values of the fifteenth through twentieth data points in `rt` (including the twentieth value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "a082e7",
     "locked": false,
     "points": 1,
     "remove": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.573962432, 0.714152493, 0.409225638, 0.435308188, 0.509801957, 0.544626271]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the values of the 15th through 20th data points in rt\n",
    "rt[14:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "a050b7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 7\n",
    "\n",
    "What is the *slowest* reaction time in `rt`? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "45367b",
     "locked": false,
     "points": 1,
     "remove": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.517088266"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is the slowest reaction time in the dataset\n",
    "max(rt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that last line of code that Copilot generated. Is it correct? Is there anything nonintuitive about it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "148042",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 8\n",
    "\n",
    "What is the *fastest* reaction time in `rt`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "656026",
     "locked": false,
     "points": 1,
     "remove": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.333356848"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is the fasted reaction time in the dataset\n",
    "min(rt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "7be11c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 9\n",
    "\n",
    "You cand find the index of a specific value in a list using the `.index()` method. Do this to find which data point (index) in `rt` has the value of 0.409225638"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "c40970",
     "locked": false,
     "points": 1,
     "remove": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find which data point in rt has the value 0.409225638\n",
    "rt.index(0.409225638)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-35e60a03d0828ac6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Accuracy Data\n",
    "\n",
    "In behavioral experiments it's common to analyze both reaction times and error rates. The list below contains a value for each trial indicating whther the subject made an error (`True`) or not (`False`). \n",
    "\n",
    "Note that it might be more intuitive if this were coded as `True` for correct responses, and `False` for errors, but the variable is recording errors, not accuracy. It's always important in data science to make sure you undersatnd what your data represent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "72c3ab",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Just run this cell; don't change anything in it\n",
    "\n",
    "err = [False, False, True, False, False, False, False, False, True, False, \n",
    "       False, True, False, False, False, False, True, True, True, False, \n",
    "       ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "a3ab29",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 10\n",
    "\n",
    "What Python data type are the *values* of `err`? (not the type of `err` itself). Use code to generate your answer, showing the type of the first entry in the `err` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "990b95",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WHAT PYTHON DATA TYPE ARE THE VALUES OF ERR   \n",
    "type(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-59b836dac95b4741",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 11\n",
    "\n",
    "How many data points do we have in `err`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-ada87234de95829b",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HOW MANY DATA POINTS ARE IN ERR\n",
    "len(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 12\n",
    "\n",
    "These data are from the same experiment/participant as the RT data, but you'll note we have fewer data points in `err`. Let's say this is because of some sort of technical error during data recording, but we know (never mind how - this is just for the assignment!) what the missing data should be. Specifically, the first data point is missing, but we know the participant made an error on that trial; and the last three data points are missing, and we know the participant got all of those trials correct. \n",
    "\n",
    "Write five lines of code, as follows:\n",
    "1. Insert a value at the beginning of `err` (without changing any of the existing values) to reflect the participant's error on the first trial.\n",
    "2. Insert three values (using one line of code) at the end of `err`, indicating correct answers on the last three trials.\n",
    "3. Print out `err` with these changes made.\n",
    "4. Print out the length of `err` \n",
    "5. Confirm that the length of `err` is now the same as the length of `rt`\n",
    "\n",
    "**Note:**: the `err` list is re-defined at the start of the cell below. Don't change this, and insert the additional lines of code that you need below it. This way, each time you run the cell you \"reset\" `err` to its original values. This is useful because if your code doesn't do what you want the first time, it may have modified `err` in ways you didn't want to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-7676ed5436269a35",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True, False, False, True, False, False, False, False, False, True, False, False, True, False, False, False, False, True, True, True, False, False, False, False]\n",
      "24\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err = [False, False, True, False, False, False, False, False, True, False, \n",
    "       False, True, False, False, False, False, True, True, True, False, \n",
    "       ]\n",
    "\n",
    "# insert a value at the beginning of err that indicates an error\n",
    "err.insert(0, True)\n",
    "\n",
    "# insert three values at the end of err that indicate correct responses\n",
    "err.extend([False, False, False])\n",
    "\n",
    "# print err\n",
    "print(err)\n",
    "\n",
    "# print the length of err\n",
    "print(len(err))\n",
    "\n",
    "# Confirm that the length of `err` is now the same as the length of `rt`\n",
    "len(err) == len(rt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True, False, False, True, False, False, False, False, False, True, False, False, True, False, False, False, False, True, True, True, False, False, False, False]\n"
     ]
    }
   ],
   "source": [
    "print(err)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "ab3834",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 13\n",
    "\n",
    "How many errors did the participant make? Use code — and specifically a list method — to generate the answer. This method was not covered in the lesson, so you may need to use the `help` command to figure out which method is approrpiate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "f01257",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many errors did the participant make\n",
    "err.count(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-31b9820ba02c9f01",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Data Cleaning\n",
    "\n",
    "It is not uncommon in behavioral studies (or other research) to have *outliers* — one or a few values that are exceptionally different from the majority of values. These can be problematic for statistical analysis, and may also not reflect the behavior we're trying to measure. For example, an RT may be exceptionally long because the participant sneezed prior to pressing the button. \n",
    "\n",
    "Above, you should have identified the longest RT in this data, which is almost 1 s longer than any other RT. We would like to remove it from the data. When we do this, we should also remove the corresponding trial's data from the error data. \n",
    "\n",
    "### Question 14\n",
    "\n",
    "Write code that does the following:\n",
    "- finds the position (index) of the slowest RT in the data\n",
    "- removes that slowest RT value from `rt`\n",
    "- removes the data from `err` that corresponds to the trial you removed in RT (i.e., has the same index)\n",
    "- prints the slowest RT remaining, rounded to two decimal places (*after* removing the outlier)\n",
    "- prints the lengths of `rt` and `err` using a single `print` command, with accompanying text to make it clear which value is the length of `rt` and which is the length of `err`\n",
    "\n",
    "Note that this can be accomplished in 5 lines of code. However, if your'e trying to figure it out yourself, without the help of an AI assistant, you might start by figuring out how to do the task without worrying how many lines of code it takes. Once you have it working, then figure out how to shorten your code if you can (think about nesting Python commands)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-4f30c64c17c5995e",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.844916827\n",
      "The length of rt is 23 and the length of err is 23\n"
     ]
    }
   ],
   "source": [
    "# find the position of the slowest RT value in rt\n",
    "rt.index(max(rt))\n",
    "\n",
    "# remove the slowest RT value from rt\n",
    "rt.remove(max(rt))\n",
    "\n",
    "# remove the corresponding error value from err\n",
    "err.pop(rt.index(max(rt)))\n",
    "\n",
    "#print the slowest RT value in rt\n",
    "print(max(rt))\n",
    "\n",
    "# print the length of rt and err using a single print statement, with accompanying test that makes it clear which value is which\n",
    "print(\"The length of rt is\", len(rt), \"and the length of err is\", len(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Copilot's Work\n",
    "\n",
    "When I typed in prompts for Copilot based on the instructions above, I got the following code:\n",
    "\n",
    "```python\n",
    "# find the position of the slowest RT value in rt\n",
    "rt.index(max(rt))\n",
    "\n",
    "# remove the slowest RT value from rt\n",
    "rt.remove(max(rt))\n",
    "\n",
    "# remove the corresponding error value from err\n",
    "err.pop(rt.index(max(rt)))\n",
    "\n",
    "#print the slowest RT value in rt\n",
    "print(max(rt))\n",
    "\n",
    "# print the length of rt and err using a single print statement, with accompanying test that makes it clear which value is which\n",
    "print(\"The length of rt is\", len(rt), \"and the length of err is\", len(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of that code is correct, in the sense that it does what I asked it to do. However, there is a logical error in the code. Can you figure out what it is? \n",
    "\n",
    "```{admonition} Click the button to reveal the solution\n",
    ":class: dropdown\n",
    "The problem is that the code removes the slowest RT value from `rt`, and *then* finds the index of the slowest RT value in `rt`. But the slowest RT value is no longer in `rt`! So the index we get for `err` is the index of the *second-slowest* RT in the original data. (Amusingly, even though Copilot generated the erroneous code, when I started typing this explanation of the error, it suggested almost the correct explanation! This actually presents some interesting possibilities for how AI assistants might be used to check their own code, which we will explore in a future lesson.)\n",
    "\n",
    "This kind of error is pernicious, in the sense that it would be very easy to make the error, and not detect it. The code correctly ends up with equal-length lists for `rt` and `err`, and each line of code *seems* to be doing what it's supposed to. It's only by really stepping through the code, and thinking about what each line is doing, that we can detect the error.\n",
    "\n",
    "To fix this, we need to find the index of the slowest RT value *before* we remove it from `rt`. Think about how you might do this (conceptually first, then in terms of code). Then write the code to do it, and/or use Copilot prompts to help you.\n",
    "\n",
    "Again, we define `rt` and `err` at the start of the cell below, so that you can run the cell multiple times to test your code.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of rt is 23 and the length of err is 23\n"
     ]
    }
   ],
   "source": [
    "rt = [0.394252808, 0.442094359, 0.534764366, 0.565906723, 0.570404592, \n",
    "      0.486154719, 0.518792127, 0.844916827, 0.495622859, 0.476159436, \n",
    "      0.612854746, 0.529661203, 0.389157455, 1.517088266, 0.573962432, \n",
    "      0.714152493, 0.409225638, 0.435308188, 0.509801957, 0.544626271, \n",
    "      0.437877745, 0.333356848, 0.401773569, 0.479840688\n",
    "      ]\n",
    "\n",
    "err = [True, False, False, True, False, False, False, False, False, True, \n",
    "       False, False, True, False, False, False, False, True, True, True, \n",
    "       False, False, False, False\n",
    "       ]\n",
    "\n",
    "# find the index of the slowest value in rt, and save it as a variable\n",
    "slowest_rt_index = rt.index(max(rt))\n",
    "\n",
    "# remove the slowest value from rt\n",
    "rt.remove(max(rt))\n",
    "\n",
    "# remove the corresponding error value from err\n",
    "err.pop(slowest_rt_index)\n",
    "\n",
    "# print the length of rt and err using a single print statement, with accompanying test that makes it clear which value is which\n",
    "print(\"The length of rt is\", len(rt), \"and the length of err is\", len(err))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4c82ffa419b871e0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Question 15\n",
    "\n",
    "Print out all the values of RT, sorted from fastest to slowest. Do not modify the original order of RT values in doing this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-dc15384fee968b89",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.333356848, 0.389157455, 0.394252808, 0.401773569, 0.409225638, 0.435308188, 0.437877745, 0.442094359, 0.476159436, 0.479840688, 0.486154719, 0.495622859, 0.509801957, 0.518792127, 0.529661203, 0.534764366, 0.544626271, 0.565906723, 0.570404592, 0.573962432, 0.612854746, 0.714152493, 0.844916827]\n"
     ]
    }
   ],
   "source": [
    "# print all the values in rt, sorted from fastest to slowest\n",
    "print(sorted(rt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "- You should now have a good sense of how to work with lists in Python, including how to access specific values, how to add values, how to remove values, and how to find the length of a list\n",
    "- You should be beginning to understand how to use Python to answer questions about your data, such as how many trials there were, or how many errors were made\n",
    "- You should also have some understanding of how to use Python to clean your data, such as by removing extreme values\n",
    "- You should also have a sense of how to use Python to check your work, such as by printing out the values of a list to make sure they are sorted correctly\n",
    "- You should be developing your ability to read code (such as that generated by Copilot) and understand what it does, and how it does it\n",
    "- You should be developing your ability to critically evaluate code, identify errors in it, and fix those errors"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
