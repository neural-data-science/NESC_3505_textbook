{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `glob()`ing: Selecting multiple filenames without hard-coding their names\n",
    "\n",
    "Often, you have many files to read in, and you don't want to type the names of every one of them. \"Hard-coding\" filenames like this is tedious and error-prone. It's also not flexible or scalable: if you collect more data or remove some bad data files, you have to manually update your list of file names. This is not a big deal if you only have three files, but it's much more work (and potential error) if you have 20, 50, 100 etc. files. \n",
    "\n",
    "Fortunately, Python has ways of listing all the files in a folder (or even in sub-folders), and using *filters* and *wildcards* to list only files whose names match specific criteria. This is done using a function called `glob()` from the package `glob` (yes, [seriously](https://docs.python.org/3/library/glob.html)). To use glob you first have to import it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`glob()` requires one argument, which is a string specifying the pattern you want to match filenames against. For example, if you wanted to use `glob()` to list one of the input files above, `s1.csv`, you would use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s1.csv']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob('s1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So you can see, `glob()` returns a list of filenames that match the string you specified. This is not terribly useful when you provide an exact file name, except it can tell you if a file is present or not. For example, if we glob a filename that doesn't exist, we get an empty list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob('ceci_nest_pas_une_file.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where `glob()` really gets useful though, is in its use of filters and wildcards. `glob()` uses Unix [**regular expressions**](https://en.wikipedia.org/wiki/Regular_expression) (regexp), which is a syntax for matching particular patterns of characters. Regexp are very powerful, but for now we'll use the simplest-but-most-powerful of them all: the wildcard, `*`.\n",
    "\n",
    "The `*` in a regexp is caleld the \"wildcard\" becuase just like a \"wild\" card in a card game - which can be used to represent any other card in the deck - `*` matches any number of any characters. So if we do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lesson5_ch2.ipynb',\n",
       " 'session_1.csv',\n",
       " 'maze_data_1.csv',\n",
       " 'maze_data_3.csv',\n",
       " 'birthday_months.csv',\n",
       " 'session_3.csv',\n",
       " 'session_2.csv',\n",
       " 'maze_data_2.csv',\n",
       " 'lesson5.md',\n",
       " 'learning_objectives.md',\n",
       " 'images',\n",
       " 'lesson5_ch1.ipynb',\n",
       " 'visuzalization.md',\n",
       " 'vis_extras.md',\n",
       " 'rt_data.csv',\n",
       " 'introduction.md',\n",
       " 'sample_data.xlsx',\n",
       " 'getting_help.md',\n",
       " 'lesson2.ipynb',\n",
       " 's2.csv',\n",
       " 's3.csv',\n",
       " 's1.csv',\n",
       " 'eye_colour.csv',\n",
       " 'study1.csv',\n",
       " 'rt_data_code.txt',\n",
       " 'lesson1.ipynb',\n",
       " 'study2.csv',\n",
       " 'data',\n",
       " 'lesson1_orig.md',\n",
       " 'fav_colour.csv']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob('*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...we get a list of all the files in the current directory, because every file name contains some number of characters. \n",
    "\n",
    "This gets useful when we combine the wildcard with a *substring* - a set of characters that appears in one or more files. For example, if we want to list all files that end with the `.csv` extension, we use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['session_1.csv',\n",
       " 'maze_data_1.csv',\n",
       " 'maze_data_3.csv',\n",
       " 'birthday_months.csv',\n",
       " 'session_3.csv',\n",
       " 'session_2.csv',\n",
       " 'maze_data_2.csv',\n",
       " 'rt_data.csv',\n",
       " 's2.csv',\n",
       " 's3.csv',\n",
       " 's1.csv',\n",
       " 'eye_colour.csv',\n",
       " 'study1.csv',\n",
       " 'study2.csv',\n",
       " 'fav_colour.csv']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob('*.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get fancier, too. For example, if we have a number of CSV files whose names all start with `study`, followed by a number, we can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['study1.csv', 'study2.csv']\n"
     ]
    }
   ],
   "source": [
    "filenames = glob('study*.csv')\n",
    "print(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, you have to be careful and check that you are being specific enough. For example, above we hard-coded the names of three files:\n",
    "`filenames = ['s1.csv', 's2.csv', 's3.csv']`\n",
    "    \n",
    "We could try using `glob()` to get the same result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['session_1.csv', 'session_3.csv', 'session_2.csv', 's2.csv', 's3.csv', 's1.csv', 'study1.csv', 'study2.csv']\n"
     ]
    }
   ],
   "source": [
    "filenames = glob('s*.csv')\n",
    "print(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...but you can see we get several other files whose names also start with `s` but have more than just a number after them. Fortunately, there's another, more restricted wildcard that matches any *single* character rather than any number of characters: `?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['s2.csv', 's3.csv', 's1.csv']\n"
     ]
    }
   ],
   "source": [
    "filenames = glob('s?.csv')\n",
    "print(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to match a specific number of characters, but you don't care what those characters are, you can use that many `?`s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s2.csv', 's3.csv', 's1.csv']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob('??.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use `glob()` to find files inside folders. For example, imagine we have a folder of data from an experimetn, which is named `data`. Inside `data`, there is a folder containing the data for one participant (named according to the participant's ID code), and each folder has a CSV file named after the participant. The naming convention for the subjects is `subj_??` where the `??` represents a two-digit ID code, starting with 01 and increasing. We can generate a list of all the data files using: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/subj_01/subj_01.csv', 'data/subj_03/subj_03.csv', 'data/subj_02/subj_02.csv', 'data/subj_05/subj_05.csv']\n"
     ]
    }
   ],
   "source": [
    "filenames = glob('data/subj_??/subj_??.csv')\n",
    "print(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note here that we use `/` to represent a subfolder. \n",
    "\n",
    "Also note that `glob()` can save us a lot of trouble, because:\n",
    "1. It scales/adapts to any number of files\n",
    "2. It makes no assumptions about the filenames, beyond what you tell it. For example, above you'll see there is no `subj_04`, but `glob()` doesn't care - it only tells you what *is* there. \n",
    "\n",
    "Conversely, hard-coding file names becomes more tedious and error-prone the more there are, and you have to carefully double-check that you don't specify the names of files you don't actually have."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
