{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c88bcae9-2be4-42d0-965f-c37d3a0f1523",
   "metadata": {},
   "source": [
    "# ASMR Preprocessing\n",
    "## Batch script\n",
    "\n",
    "Should be a (roughly identical) copy of the .py script of the same name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "surprising-procurement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------\n",
      "-------- ASMR_02 --------\n",
      "-------------------------\n",
      "Estimating rejection dictionary for eeg\n",
      "Estimating rejection dictionary for eog\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   2 out of   6 | elapsed:    9.2s remaining:   18.3s\n",
      "[Parallel(n_jobs=6)]: Done   3 out of   6 | elapsed:    9.2s remaining:    9.2s\n",
      "[Parallel(n_jobs=6)]: Done   4 out of   6 | elapsed:    9.2s remaining:    4.6s\n",
      "[Parallel(n_jobs=6)]: Done   6 out of   6 | elapsed:    9.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done   6 out of   6 | elapsed:    9.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n epochs removed: 0\n",
      "representing 0.0 % of data\n",
      "Overwriting existing file.\n",
      "\n",
      "-------------------------\n",
      "-------- ASMR_03 --------\n",
      "-------------------------\n",
      "Estimating rejection dictionary for eeg\n",
      "Estimating rejection dictionary for eog\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   2 out of   6 | elapsed:    8.1s remaining:   16.2s\n",
      "[Parallel(n_jobs=6)]: Done   3 out of   6 | elapsed:    8.1s remaining:    8.1s\n",
      "[Parallel(n_jobs=6)]: Done   4 out of   6 | elapsed:    8.2s remaining:    4.1s\n",
      "[Parallel(n_jobs=6)]: Done   6 out of   6 | elapsed:    8.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done   6 out of   6 | elapsed:    8.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n epochs removed: 21\n",
      "representing 7.72 % of data\n",
      "Overwriting existing file.\n",
      "\n",
      "-------------------------\n",
      "-------- ASMR_05 --------\n",
      "-------------------------\n",
      "Estimating rejection dictionary for eeg\n",
      "Estimating rejection dictionary for eog\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   2 out of   6 | elapsed:    8.8s remaining:   17.6s\n",
      "[Parallel(n_jobs=6)]: Done   3 out of   6 | elapsed:    8.8s remaining:    8.8s\n",
      "[Parallel(n_jobs=6)]: Done   4 out of   6 | elapsed:    8.9s remaining:    4.4s\n",
      "[Parallel(n_jobs=6)]: Done   6 out of   6 | elapsed:    9.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done   6 out of   6 | elapsed:    9.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n epochs removed: 5\n",
      "representing 2.7 % of data\n",
      "Overwriting existing file.\n",
      "\n",
      "-------------------------\n",
      "-------- ASMR_07 --------\n",
      "-------------------------\n",
      "Estimating rejection dictionary for eeg\n",
      "Estimating rejection dictionary for eog\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   2 out of   6 | elapsed:    8.4s remaining:   16.8s\n",
      "[Parallel(n_jobs=6)]: Done   3 out of   6 | elapsed:    8.4s remaining:    8.4s\n",
      "[Parallel(n_jobs=6)]: Done   4 out of   6 | elapsed:    8.4s remaining:    4.2s\n",
      "[Parallel(n_jobs=6)]: Done   6 out of   6 | elapsed:    8.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done   6 out of   6 | elapsed:    8.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n epochs removed: 0\n",
      "representing 0.0 % of data\n",
      "Overwriting existing file.\n",
      "\n",
      "-------------------------\n",
      "-------- ASMR_09 --------\n",
      "-------------------------\n",
      "Estimating rejection dictionary for eeg\n",
      "Estimating rejection dictionary for eog\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   2 out of   6 | elapsed:    8.5s remaining:   16.9s\n",
      "[Parallel(n_jobs=6)]: Done   3 out of   6 | elapsed:    8.5s remaining:    8.5s\n",
      "[Parallel(n_jobs=6)]: Done   4 out of   6 | elapsed:    8.5s remaining:    4.3s\n",
      "[Parallel(n_jobs=6)]: Done   6 out of   6 | elapsed:    8.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done   6 out of   6 | elapsed:    8.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n epochs removed: 8\n",
      "representing 2.9 % of data\n",
      "Overwriting existing file.\n",
      "\n",
      "-------------------------\n",
      "-------- ASMR_10 --------\n",
      "-------------------------\n",
      "Estimating rejection dictionary for eeg\n",
      "Estimating rejection dictionary for eog\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   2 out of   6 | elapsed:    8.0s remaining:   16.0s\n",
      "[Parallel(n_jobs=6)]: Done   3 out of   6 | elapsed:    8.0s remaining:    8.0s\n",
      "[Parallel(n_jobs=6)]: Done   4 out of   6 | elapsed:    8.0s remaining:    4.0s\n",
      "[Parallel(n_jobs=6)]: Done   6 out of   6 | elapsed:    8.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done   6 out of   6 | elapsed:    8.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n epochs removed: 0\n",
      "representing 0.0 % of data\n",
      "Overwriting existing file.\n",
      "\n",
      "-------------------------\n",
      "-------- ASMR_11 --------\n",
      "-------------------------\n",
      "Estimating rejection dictionary for eeg\n",
      "Estimating rejection dictionary for eog\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   2 out of   6 | elapsed:    8.6s remaining:   17.3s\n",
      "[Parallel(n_jobs=6)]: Done   3 out of   6 | elapsed:    8.7s remaining:    8.7s\n",
      "[Parallel(n_jobs=6)]: Done   4 out of   6 | elapsed:    8.7s remaining:    4.4s\n",
      "[Parallel(n_jobs=6)]: Done   6 out of   6 | elapsed:    8.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done   6 out of   6 | elapsed:    8.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n epochs removed: 0\n",
      "representing 0.0 % of data\n",
      "Overwriting existing file.\n",
      "\n",
      "-------------------------\n",
      "-------- ASMR_13 --------\n",
      "-------------------------\n",
      "Estimating rejection dictionary for eeg\n",
      "Estimating rejection dictionary for eog\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   2 out of   6 | elapsed:    8.0s remaining:   15.9s\n",
      "[Parallel(n_jobs=6)]: Done   3 out of   6 | elapsed:    8.0s remaining:    8.0s\n",
      "[Parallel(n_jobs=6)]: Done   4 out of   6 | elapsed:    8.0s remaining:    4.0s\n",
      "[Parallel(n_jobs=6)]: Done   6 out of   6 | elapsed:    8.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done   6 out of   6 | elapsed:    8.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n epochs removed: 0\n",
      "representing 0.0 % of data\n",
      "Overwriting existing file.\n",
      "\n",
      "-------------------------\n",
      "-------- ASMR_16 --------\n",
      "-------------------------\n",
      "Estimating rejection dictionary for eeg\n",
      "Estimating rejection dictionary for eog\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   2 out of   6 | elapsed:    9.8s remaining:   19.6s\n",
      "[Parallel(n_jobs=6)]: Done   3 out of   6 | elapsed:    9.8s remaining:    9.8s\n",
      "[Parallel(n_jobs=6)]: Done   4 out of   6 | elapsed:    9.9s remaining:    4.9s\n",
      "[Parallel(n_jobs=6)]: Done   6 out of   6 | elapsed:    9.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done   6 out of   6 | elapsed:    9.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n epochs removed: 0\n",
      "representing 0.0 % of data\n",
      "Overwriting existing file.\n",
      "\n",
      "-------------------------\n",
      "-------- ASMR_17 --------\n",
      "-------------------------\n",
      "Estimating rejection dictionary for eeg\n",
      "Estimating rejection dictionary for eog\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   2 out of   6 | elapsed:    8.3s remaining:   16.7s\n",
      "[Parallel(n_jobs=6)]: Done   3 out of   6 | elapsed:    8.4s remaining:    8.4s\n",
      "[Parallel(n_jobs=6)]: Done   4 out of   6 | elapsed:    8.4s remaining:    4.2s\n",
      "[Parallel(n_jobs=6)]: Done   6 out of   6 | elapsed:    8.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done   6 out of   6 | elapsed:    8.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n epochs removed: 1\n",
      "representing 2.22 % of data\n",
      "Overwriting existing file.\n",
      "\n",
      "-------------------------\n",
      "-------- ASMR_19 --------\n",
      "-------------------------\n",
      "Estimating rejection dictionary for eeg\n",
      "Estimating rejection dictionary for eog\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   2 out of   6 | elapsed:    8.5s remaining:   17.0s\n",
      "[Parallel(n_jobs=6)]: Done   3 out of   6 | elapsed:    8.5s remaining:    8.5s\n",
      "[Parallel(n_jobs=6)]: Done   4 out of   6 | elapsed:    8.5s remaining:    4.3s\n",
      "[Parallel(n_jobs=6)]: Done   6 out of   6 | elapsed:    8.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done   6 out of   6 | elapsed:    8.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n epochs removed: 0\n",
      "representing 0.0 % of data\n",
      "Overwriting existing file.\n",
      "\n",
      "-------------------------\n",
      "-------- ASMR_21 --------\n",
      "-------------------------\n",
      "Estimating rejection dictionary for eeg\n",
      "Estimating rejection dictionary for eog\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   2 out of   6 | elapsed:    9.1s remaining:   18.3s\n",
      "[Parallel(n_jobs=6)]: Done   3 out of   6 | elapsed:    9.2s remaining:    9.2s\n",
      "[Parallel(n_jobs=6)]: Done   4 out of   6 | elapsed:    9.2s remaining:    4.6s\n",
      "[Parallel(n_jobs=6)]: Done   6 out of   6 | elapsed:    9.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=6)]: Done   6 out of   6 | elapsed:    9.3s finished\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "list.remove(x): x not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/x0/pvpjfdzd39sc5rqvsk5lvv4m0000gn/T/ipykernel_83805/3492448208.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msubject\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'ASMR_21'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mic\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m             \u001b[0mica\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msubject\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'ASMR_22'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mic\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m22\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: list.remove(x): x not in list"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rcParams['figure.dpi'] = 72\n",
    "\n",
    "# from os import path, mkdir\n",
    "import os\n",
    "import mne\n",
    "from mne.viz.ica import _prepare_data_ica_properties\n",
    "mne.set_log_level('error')\n",
    "from scipy.stats import zscore\n",
    "from autoreject import Ransac, get_rejection_threshold, AutoReject\n",
    "\n",
    "### Set parameters\n",
    "\n",
    "# PERMANENTLY EXCLUDE 'ASMR_08' & ASMR_14 & 'ASMR_18' because they had no reports of ASMR that lasted > 1 s each\n",
    "# Likewise, ASMR_01 and ASMR_20 have 0-1 ASMR events after preprocessing\n",
    "subjects = ['ASMR_02', 'ASMR_03', 'ASMR_05', \n",
    "            'ASMR_07', \n",
    "            'ASMR_09',\n",
    "            'ASMR_10', 'ASMR_11',\n",
    "            'ASMR_13','ASMR_16', 'ASMR_17', \n",
    "            'ASMR_19', \n",
    "            'ASMR_21', 'ASMR_22',\n",
    "           ]\n",
    "\n",
    "# for all multi-threaded operations\n",
    "n_jobs = 6\n",
    "\n",
    "# Filter settings\n",
    "l_freq = 0.1\n",
    "h_freq = 50.0\n",
    "l_freq_ica = 1.\n",
    "l_trans_bandwidth = 'auto'\n",
    "h_trans_bandwidth = 'auto'\n",
    "filter_length='auto'\n",
    "filter_method = 'fir'\n",
    "filter_picks = ['eeg', 'eog', 'bio']\n",
    "\n",
    "rej_log_list = []\n",
    "\n",
    "# ICA settings\n",
    "ica_random_state = 42  # seed so ICA is reproducable each time it's run\n",
    "n_components = .995     # Specify n_components as a decimal to set % explained variance\n",
    "ica_zthresh = 3.291\n",
    "\n",
    "# Events\n",
    "# Note: ASMRcontrol trials and codes will be defined later\n",
    "event_id = {'video1':1, 'video2':2,\n",
    "            'video3':3, 'video4':4,\n",
    "            'video5':5, 'video6':6,\n",
    "            'rest_start':7, 'rest':8,\n",
    "            'video_end':25,\n",
    "            'ASMRbutton/start':64, 'ASMR': 65, 'ASMRbutton/end':128,\n",
    "            'ASMRctrl':66\n",
    "           }\n",
    "\n",
    "\n",
    "cond_of_interest = sorted(['ASMRstart','ASMRcontrol','rest'])\n",
    "\n",
    "rest_duration = 30 * 1000 # convert s to ms\n",
    "rest_interval =  1 * 1000\n",
    "\n",
    "# Epoching settings\n",
    "tmin = -1.0  # start of each epoch (in sec)\n",
    "tmax =  1.0  # end of each epoch (in sec)\n",
    "baseline = None  #(None, 0)\n",
    "detrend = 0\n",
    "reject = None\n",
    "flat = None\n",
    "\n",
    "# standard montage file to look up channel locations\n",
    "montage_fname = 'standard_1005'\n",
    "\n",
    "out_path = '../'\n",
    "epo_path = out_path + 'Epochs/'\n",
    "\n",
    "if not os.path.exists(out_path):\n",
    "    os.mkdir(out_path)\n",
    "if not os.path.exists(epo_path):\n",
    "    os.mkdir(epo_path)\n",
    "\n",
    "for subject in subjects:\n",
    "    print('\\n-------------------------')\n",
    "    print('-------- ' + subject + ' --------')\n",
    "    print('-------------------------')\n",
    "    ### Subject-specific paramters\n",
    "    # Where to find and save files\n",
    "    data_path = '../../EEG data/' + subject + '/'\n",
    "    log_path = out_path + 'preprocessing logs/' + subject + '/'\n",
    "    if not os.path.exists(log_path):\n",
    "        os.mkdir(log_path)\n",
    "    else:\n",
    "        for filename in os.listdir(log_path):\n",
    "            file_path = os.path.join(log_path, filename)\n",
    "            try:\n",
    "                if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                    os.unlink(file_path)\n",
    "                elif os.path.isdir(file_path):\n",
    "                    shutil.rmtree(file_path)\n",
    "            except Exception as e:\n",
    "                print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
    "\n",
    "                \n",
    "    # output file names - set to follow MNE conventions\n",
    "    epochs_fname  = epo_path + subject + '-epo.fif'\n",
    "    # psd_data_fname = csv_path + subject + '-psd.csv'\n",
    "    asmr_reports_fname = log_path + subject + '_ASMR_reports.csv'\n",
    "\n",
    "    ### Subject-specific hacks\n",
    "    if subject=='ASMR_20':\n",
    "        n_components = .9999\n",
    "        \n",
    "    ### Import data\n",
    "    raw_fname = data_path + subject + '.vhdr'\n",
    "    raw = mne.io.read_raw_brainvision(raw_fname,\n",
    "                                        preload=True,\n",
    "                                       )\n",
    "    raw.set_channel_types({'HEOG':'eog','VEOG':'eog','GSR':'bio'})\n",
    "    raw.set_montage(montage_fname)\n",
    "\n",
    "    \n",
    "    ### Event processing #######################################################################\n",
    "    events, event_dict = mne.events_from_annotations(raw)\n",
    "\n",
    "    ##################################\n",
    "    # CODE PROCESSING\n",
    "    ##################################\n",
    "    ## Create epochs from rest period\n",
    "\n",
    "    r_starts = np.squeeze(np.where(events[:, 2] == event_id['rest_start']))\n",
    "    trial_ends = np.squeeze(np.where(events[:, 2] == event_id['video_end']))\n",
    "    # trial_ends include both rest blocks and ASMR videos; find only ends of rest blocks\n",
    "    r_ends = np.squeeze(trial_ends[np.searchsorted(trial_ends, r_starts)])\n",
    "\n",
    "    r_idx = np.column_stack((r_starts, r_ends))\n",
    "    r_intvl = events[r_idx, 0]\n",
    "\n",
    "    r_segs = []\n",
    "    for i in r_intvl:\n",
    "        r_segs.append(np.arange(i[0], i[1]-rest_interval, rest_interval))\n",
    "\n",
    "    r_segs = np.concatenate(r_segs)    \n",
    "    rest_events = np.transpose([r_segs, \n",
    "                                np.tile(0, len(r_segs)), \n",
    "                                np.tile(event_id['rest'], len(r_segs))\n",
    "                               ])\n",
    "\n",
    "    ####################\n",
    "    ## Find ASMR AND CONTROL events\n",
    "\n",
    "    asmr_events = []\n",
    "    ctrl_events = []\n",
    "\n",
    "    # find events marking start of ASMR videos\n",
    "    v_starts = np.squeeze(np.where((events[:, 2] > 0)  & (events[:, 2] < 7)))\n",
    "    trial_ends = np.where(events[:, 2] == event_id['video_end'])[0]\n",
    "    # trial_ends include both control and ASMR videos; find only ends of ASMR videos\n",
    "    v_ends = trial_ends[np.searchsorted(trial_ends, v_starts)]\n",
    "\n",
    "    for v_num, v_start_idx in np.ndenumerate(v_starts):\n",
    "        v_end_idx = v_ends[v_num] + 1\n",
    "        # create array of codes in this video, INCLUDING video start code, and including video end code\n",
    "        this_vid = events[v_start_idx:v_end_idx, :]\n",
    "        vid_num = this_vid[0, 2]\n",
    "\n",
    "        # find start of ASMR periods\n",
    "        asmr_starts = np.squeeze(np.where((this_vid[:, 2] == event_id['ASMRbutton/start']) ))\n",
    "        # find instances of two 'start' button presses in a row\n",
    "        dbl_starts = asmr_starts[this_vid[asmr_starts-1, 2] == event_id['ASMRbutton/start']]\n",
    "        # remove the doubled rows\n",
    "        this_vid = np.delete(this_vid, dbl_starts, axis=0)\n",
    "\n",
    "        asmr_ends = np.squeeze(np.where((this_vid[:, 2] == event_id['ASMRbutton/end'])))\n",
    "        dbl_ends = asmr_ends[this_vid[asmr_ends-1, 2] == event_id['ASMRbutton/end']]\n",
    "        # remove the doubled rows\n",
    "        this_vid = np.delete(this_vid, dbl_ends, axis=0)\n",
    "        # update \n",
    "        asmr_starts = np.squeeze(np.where(this_vid[:, 2] == event_id['ASMRbutton/start']))\n",
    "        asmr_ends = np.squeeze(np.where((this_vid[:, 2] == event_id['ASMRbutton/end']) | (this_vid[:, 2] == event_id['video_end'])))\n",
    "\n",
    "        ctrl_starts = np.squeeze(np.where((this_vid[:, 2] == event_id['ASMRbutton/end']) | (this_vid[:, 2] == vid_num)))\n",
    "        ctrl_ends   = np.squeeze(np.where((this_vid[:, 2] == event_id['ASMRbutton/start']) | (this_vid[:, 2] == event_id['video_end'])))\n",
    "\n",
    "        if (asmr_starts.ndim == 0):\n",
    "            asmr_starts = np.reshape(asmr_starts, 1)\n",
    "\n",
    "        if asmr_starts.size != 0:     \n",
    "\n",
    "            if this_vid[-2, 2] != event_id['ASMRbutton/start']:\n",
    "                asmr_ends = asmr_ends[:-1]\n",
    "\n",
    "            asmr_durations = this_vid[asmr_ends, 0] - this_vid[asmr_starts, 0]\n",
    "            asmr_seg_len = asmr_durations // 1000\n",
    "\n",
    "            for idx in range(len(asmr_starts + 1)):\n",
    "                event = this_vid[asmr_starts[idx]]\n",
    "\n",
    "                for seg in range(asmr_seg_len[idx]):\n",
    "                    asmr_events.append([event[0] + (seg * 1000), \n",
    "                                       0, \n",
    "                                       event_id['ASMR']\n",
    "                                      ])\n",
    "            # remove last \"end\" if video ended during ASMR period. Only needed if ASMR happened\n",
    "            if(len(ctrl_ends) > len(ctrl_starts)):\n",
    "                ctrl_ends = ctrl_ends[:-1]\n",
    "\n",
    "        ctrl_durations = this_vid[ctrl_ends, 0] - this_vid[ctrl_starts, 0]\n",
    "        ctrl_seg_len = ctrl_durations // 1000\n",
    "\n",
    "        if ctrl_starts.ndim == 0:\n",
    "            ctrl_starts = ctrl_starts.reshape([1])\n",
    "            ctrl_ends = ctrl_ends.reshape([1])\n",
    "            ctrl_seg_len = ctrl_seg_len.reshape([1])\n",
    "\n",
    "\n",
    "\n",
    "        for idx in range(len(ctrl_starts + 1)):\n",
    "            event = this_vid[ctrl_starts[idx]]\n",
    "\n",
    "            for seg in range(ctrl_seg_len[idx]):\n",
    "                ctrl_events.append([event[0] + (seg * 1000), \n",
    "                                   0, \n",
    "                                   event_id['ASMRctrl']\n",
    "                                  ])\n",
    "\n",
    "\n",
    "    asmr_events = np.asarray(asmr_events)    \n",
    "    ctrl_events = np.asarray(ctrl_events)         \n",
    "    ## Combine into new events array\n",
    "    events_new = np.vstack((rest_events, asmr_events, ctrl_events))\n",
    "    # sort by time\n",
    "    events_new = events_new[events_new[:, 0].argsort()] \n",
    "    mne.write_events(log_path + subject + '_events.tsv', events_new)\n",
    "\n",
    "    # Reduce event_id to events retained after rejection\n",
    "    event_id_new = {}\n",
    "    for key, value in event_id.items():\n",
    "        if np.isin(value, np.unique(events_new[:, 2])):\n",
    "            event_id_new[key] = value\n",
    "\n",
    "    # export plot of events\n",
    "    matplotlib.rcParams['lines.markersize'] = 2\n",
    "    matplotlib.rcParams['figure.figsize'] = (45, 3)\n",
    "    fig = mne.viz.plot_events(events_new, raw.info['sfreq'], event_id=event_id_new, show=False)  \n",
    "    fig.savefig(log_path + subject + '_event_timing.png');\n",
    "    plt.close(fig)\n",
    "    # End of event code processing section #####\n",
    "    ############################################\n",
    "    \n",
    "    ### Data Cleaning\n",
    "    # Filter for ICA\n",
    "    raw_ica = raw.copy().filter(l_freq_ica, h_freq,\n",
    "                            l_trans_bandwidth = l_trans_bandwidth,\n",
    "                            h_trans_bandwidth = h_trans_bandwidth,\n",
    "                            filter_length=filter_length,\n",
    "                            method='fft',\n",
    "                            picks = mne.pick_types(raw.info, eeg=True, eog=True),\n",
    "                            n_jobs = n_jobs)\n",
    "\n",
    "    # Filter for final\n",
    "    raw_filt = raw.copy().filter(l_freq, h_freq,\n",
    "                                 l_trans_bandwidth = l_trans_bandwidth,\n",
    "                                 h_trans_bandwidth = h_trans_bandwidth,\n",
    "                                 filter_length=filter_length,\n",
    "                                 method=filter_method,\n",
    "                                 picks = filter_picks,\n",
    "                                 n_jobs = n_jobs)\n",
    "\n",
    "    fig = raw_filt.plot_psd(fmax=80, n_jobs=n_jobs, average=False, spatial_colors=True, show=False);\n",
    "    fig.savefig(log_path + subject + '_filtered_psd.png');\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Break raw data into 1 s epochs for autoreject\n",
    "    tstep = 1.0\n",
    "    events_ica = mne.make_fixed_length_events(raw_ica, duration=tstep)\n",
    "    epochs_ica = mne.Epochs(raw_ica, events_ica,\n",
    "                            tmin=0.0, tmax=tstep,\n",
    "                            baseline=None,\n",
    "                            preload=True)\n",
    "    ### Find appropriate rejection threshold to eliminate noisy trials from ICA fitting\n",
    "    reject = get_rejection_threshold(epochs_ica)\n",
    "\n",
    "    # Find and mark bad channels to be ignored by ICA\n",
    "    ransac = Ransac(n_jobs=n_jobs, random_state=ica_random_state, verbose=False)\n",
    "    ransac.fit(epochs_ica)\n",
    "    epochs_ica.info['bads'] = ransac.bad_chs_\n",
    "\n",
    "    # Fit ICA\n",
    "    ica = mne.preprocessing.ICA(n_components=n_components,\n",
    "                                random_state=ica_random_state,\n",
    "                                max_iter='auto')\n",
    "    ica.fit(epochs_ica,\n",
    "            reject=reject,\n",
    "            tstep=tstep)\n",
    "\n",
    "    fig = ica.plot_components(show=False);\n",
    "    for f_idx, f in enumerate(fig):\n",
    "        f.savefig(log_path + subject + '_ica_topomaps' + str(f_idx) + '.png');\n",
    "        plt.close(f)\n",
    "        \n",
    "    # Identify ocular ICs\n",
    "    # At least for our ASMR dataset, the default *z* threshold doesn't work for\n",
    "    # all subjects. This routine starts with the default (*z* = 3) and steps down\n",
    "    # until at least 2 EOG components are identified.\n",
    "    # The issue with this is that it assumes there will always be at least 2 EOG\n",
    "    # components (blinks are always present, but horizontal movements are not\n",
    "    # always present), and may not work if there are > 3 components, if the\n",
    "    # score of the third is > `z_step` less than the score of the second.\n",
    "    ica.exclude = []\n",
    "    num_excl = 0\n",
    "    z_thresh = 3.0\n",
    "    z_step = 0.2 # decrement zthresh by this much each time\n",
    "\n",
    "    while num_excl < 2:\n",
    "        eog_indices, eog_scores = ica.find_bads_eog(raw_ica,threshold=z_thresh)\n",
    "        num_excl = len(eog_indices)\n",
    "        z_thresh -= z_step # won't impact things if num_excl is 2 or more\n",
    "\n",
    "    ica.exclude = eog_indices\n",
    "    z_thresh_final = round(z_thresh + z_step, 2)\n",
    "\n",
    "    # Find components where at least 1 electrode has a z score > ica_zthresh (conventionally z â‰¤ 2.96, p < .05)\n",
    "    comp_dat = ica.get_components()\n",
    "    ica_zscores = abs(zscore(comp_dat, axis=1))   \n",
    "    outlier_comps = np.where([max(ica_zscores[:, i]) > ica_zthresh for i in range(ica_zscores.shape[1])])[0].tolist()\n",
    "    ica.exclude.extend(outlier_comps)\n",
    "    ica_zscores = pd.DataFrame(ica_zscores)\n",
    "    ica_zscores.to_csv(log_path + subject + 'ica_zscores.csv')\n",
    "\n",
    "    # Manual removal/re-addition of ICs based on visual inspection\n",
    "    # (this is a kluge until we have a better automated IC classification system)\n",
    "    if subject == 'ASMR_10':\n",
    "        ica.exclude.remove(10)\n",
    "    if subject == 'ASMR_19':\n",
    "        for ic in [4, 6]:\n",
    "            ica.exclude.remove(ic)\n",
    "    if subject == 'ASMR_21':\n",
    "        for ic in [7]:\n",
    "            ica.exclude.remove(ic)\n",
    "    if subject == 'ASMR_22':\n",
    "        for ic in [3, 5, 10, 11, 22]:\n",
    "            ica.exclude.remove(ic)\n",
    "\n",
    "    # barplot of ICA component \"EOG match\" scores\n",
    "    fig = ica.plot_scores(eog_scores, show=False);\n",
    "    fig.savefig(log_path + subject + '_ica_score.png');\n",
    "    plt.close(fig)\n",
    "\n",
    "    # plot diagnostics\n",
    "    for i in ica.exclude:\n",
    "        fig = ica.plot_properties(raw_ica, picks=i, psd_args={'fmax': h_freq}, show=False);\n",
    "        fig[0].savefig(log_path + subject + '_ica_eog_' + str(i) + '.png');\n",
    "        plt.close(fig[0])\n",
    "\n",
    "    #### Segment filtered raw data into epochs for final analysis\n",
    "    epochs = mne.Epochs(raw_filt,\n",
    "                        events_new, event_id_new,\n",
    "                        tmin, tmax,\n",
    "                        baseline=baseline, detrend=detrend,\n",
    "                        reject=reject, flat=None,\n",
    "                        preload=True\n",
    "                       )\n",
    "\n",
    "    # Apply ICA correction to epochs\n",
    "    epochs_postica = ica.apply(epochs.copy())\n",
    "    epochs_postica.info['bads'] = ransac.bad_chs_\n",
    "    epochs_postica = epochs_postica.interpolate_bads()\n",
    "\n",
    "    # Apply AutoReject to clean epochs\n",
    "    ar = AutoReject(n_jobs=n_jobs, random_state=ica_random_state, verbose=False)\n",
    "    epochs_clean = ar.fit_transform(epochs_postica)\n",
    "    # Re-reference to average of all channels, now that they are cleaned\n",
    "    epochs_clean.set_eeg_reference(ref_channels='average');\n",
    "\n",
    "    # Report on how much was rejected\n",
    "    rm_epochs = epochs_postica.selection.shape[0] - epochs_clean.selection.shape[0]\n",
    "    pct_epochs = rm_epochs / epochs_postica.selection.shape[0] * 100\n",
    "    print('n epochs removed: ' + str(rm_epochs)\n",
    "          + '\\nrepresenting ' + str(round(pct_epochs, 2)) + ' % of data')\n",
    "\n",
    "    # Save log of rejections\n",
    "    rej_log_list.append(pd.DataFrame({'Subject':subject,\n",
    "                                      'n Trials Rej':rm_epochs,\n",
    "                                      '% Trials Rej':round(pct_epochs, 2),\n",
    "                                      'n Chans Fixed':len(epochs_ica.info['bads']),\n",
    "                                      'n ICs removed':len(ica.exclude)\n",
    "                                      }, index=[0])\n",
    "                         )\n",
    "\n",
    "\n",
    "\n",
    "    # Save cleaned epochs\n",
    "    epochs_clean.save(epochs_fname, overwrite=True)\n",
    "\n",
    "    fig = epochs_clean.average().plot(spatial_colors=True, show=False);\n",
    "    fig.savefig(log_path + subject + '_epochs_avg.png');\n",
    "    plt.close(fig)\n",
    "\n",
    "rej_log = pd.concat(rej_log_list, ignore_index=True)\n",
    "rej_log.to_csv(log_path + 'ASMR_rej_log.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "planned-groove",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Variance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hidden-electric",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "picks = range(ica.n_components_)\n",
    "kind, dropped_indices, epochs_src, data = _prepare_data_ica_properties(\n",
    "    epochs_ica, ica)\n",
    "ica_data = np.swapaxes(data[:, picks, :], 0, 1)\n",
    "dropped_src = ica_data\n",
    "\n",
    "# fig, ax = plt.subplots(ica.n_components_, 1)\n",
    "for idx in picks:\n",
    "    epoch_var = np.var(ica_data[idx], axis=1)\n",
    "    drop_var = np.var(dropped_src[idx], axis=1)\n",
    "    drop_indices_corrected = \\\n",
    "        (dropped_indices -\n",
    "         np.arange(len(dropped_indices))).astype(int)\n",
    "    epoch_var = np.insert(arr=epoch_var,\n",
    "                          obj=drop_indices_corrected,\n",
    "                          values=drop_var[dropped_indices],\n",
    "                          axis=0)\n",
    "    plt.hist(zscore(epoch_var), density=True)\n",
    "    plt.title('IC ' + str(idx))\n",
    "    plt.yscale('log')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
